<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 3.2.0">
  <meta name="generator" content="Hugo 0.52" />
  <meta name="author" content="Brandon Wood">

  
  
  
  
    
  
  <meta name="description" content="Introduction Since the end of my PhD, I have been interested in coupling active learning with quantum calculations to explore configuration space in molecular systems. The goal of this post is to demonstrate active learning on a simple system and to put a few ideas out there for people to think about and expand on. Another reason I wanted to make this post is that I think it is ridiculously cool how seamlessly GraphDot/xTB/ASE can work together.">

  
  <link rel="alternate" hreflang="en-us" href="https://wood-b.github.io/post/active_learn_pe/">

  


  

  

  

  

  

  

  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha256-eSi1q2PG6J7g7ib17yAaWMcrr5GrtohYChqibrV7PBE=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css" integrity="sha384-5sAR7xN1Nv6T6+dT2mhtzEpVJvfS3NScPQTrOxhwjIuvcA67KV2R5Jz6kr4abQsz" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" crossorigin="anonymous">
        
      
    

    

    

  

  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700|Roboto:400,400italic,700|Roboto+Mono">
  

  <link rel="stylesheet" href="/styles.css">
  

  
  
  

  
  <link rel="alternate" href="https://wood-b.github.io/index.xml" type="application/rss+xml" title="">
  <link rel="feed" href="https://wood-b.github.io/index.xml" type="application/rss+xml" title="">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://wood-b.github.io/post/active_learn_pe/">

  
  
  
  
    
    
  
  <meta property="twitter:card" content="summary">
  
  <meta property="og:site_name" content="">
  <meta property="og:url" content="https://wood-b.github.io/post/active_learn_pe/">
  <meta property="og:title" content="Active Learning on Molecular Systems with GraphDot, xTB, ASE, and scikit-learn | ">
  <meta property="og:description" content="Introduction Since the end of my PhD, I have been interested in coupling active learning with quantum calculations to explore configuration space in molecular systems. The goal of this post is to demonstrate active learning on a simple system and to put a few ideas out there for people to think about and expand on. Another reason I wanted to make this post is that I think it is ridiculously cool how seamlessly GraphDot/xTB/ASE can work together."><meta property="og:image" content="https://wood-b.github.io/img/my_pic.jpg">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2020-03-11T22:10:34-07:00">
  
  <meta property="article:modified_time" content="2020-03-11T22:10:34-07:00">
  

  

  

  <title>Active Learning on Molecular Systems with GraphDot, xTB, ASE, and scikit-learn | </title>

</head>
<body id="top" data-spy="scroll" data-target="#TableOfContents" data-offset="71" >
  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" role="textbox" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/"></a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav ml-auto">
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#projects">
            
            <span>Projects</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#publications">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#posts">
            
            <span>Posts</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/files/cv_website_feb2020.pdf">
            
            <span>CV</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#contact">
            
            <span>Contact</span>
            
          </a>
        </li>

        
        

      

        

        
        <li class="nav-item">
          <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        

        
        <li class="nav-item">
          <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
        </li>
        

      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  












  

  
  
  
<div class="article-container pt-3">
  <h1 itemprop="name">Active Learning on Molecular Systems with GraphDot, xTB, ASE, and scikit-learn</h1>

  

  
    

<div class="article-metadata">

  
  
  
  <div>
    <span itemscope itemprop="author" itemtype="http://schema.org/Person">
      <span itemprop="name">Brandon M. Wood</span>
    </span>
    
  </div>
  

  <span class="article-date">
    
    <meta content="2020-03-11 22:10:34 -0700 PDT" itemprop="datePublished">
    <time datetime="2020-03-11 22:10:34 -0700 PDT" itemprop="dateModified">
      Mar 11, 2020
    </time>
  </span>
  <span itemscope itemprop="publisher" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Brandon Wood">
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    11 min read
  </span>
  

  
  

  

  
  
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=Active%20Learning%20on%20Molecular%20Systems%20with%20GraphDot%2c%20xTB%2c%20ASE%2c%20and%20scikit-learn&amp;url=https%3a%2f%2fwood-b.github.io%2fpost%2factive_learn_pe%2f"
         target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fwood-b.github.io%2fpost%2factive_learn_pe%2f"
         target="_blank" rel="noopener">
        <i class="fab fa-facebook-f"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fwood-b.github.io%2fpost%2factive_learn_pe%2f&amp;title=Active%20Learning%20on%20Molecular%20Systems%20with%20GraphDot%2c%20xTB%2c%20ASE%2c%20and%20scikit-learn"
         target="_blank" rel="noopener">
        <i class="fab fa-linkedin-in"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=https%3a%2f%2fwood-b.github.io%2fpost%2factive_learn_pe%2f&amp;title=Active%20Learning%20on%20Molecular%20Systems%20with%20GraphDot%2c%20xTB%2c%20ASE%2c%20and%20scikit-learn"
         target="_blank" rel="noopener">
        <i class="fab fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=Active%20Learning%20on%20Molecular%20Systems%20with%20GraphDot%2c%20xTB%2c%20ASE%2c%20and%20scikit-learn&amp;body=https%3a%2f%2fwood-b.github.io%2fpost%2factive_learn_pe%2f">
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


  

</div>

    







  









  
</div>



  <div class="article-container">

    <div class="article-style" itemprop="articleBody">
      

<h2 id="introduction">Introduction</h2>

<p>Since the end of my PhD, I have been interested in coupling active learning with quantum calculations to explore configuration space in molecular systems. The goal of this post is to demonstrate active learning on a simple system and to put a few ideas out there for people to think about and expand on. Another reason I wanted to make this post is that I think it is ridiculously cool how seamlessly GraphDot/xTB/ASE can work together.</p>

<p>I want to thank <a href="https://crd.lbl.gov/departments/computational-science/ccmc/staff/alvarez-fellows/yu-hang-tang/" target="_blank">Yu-Hang Tang</a> for all the help with the graph kernel, none of this would have been possible otherwise. If you want to learn more about the graph kernel, check out this <a href="http://dx.doi.org/10.1063/1.5078640" target="_blank">publication</a>.</p>

<p>If you have any questions or comments shoot me an email bwood@lbl.gov.</p>

<h2 id="dependencies">Dependencies:</h2>

<p>All dependencies can be pip installed with the exception of xTB, which could be replaced with a different energy calculator if necessary.<br />
- <a href="https://graphdot.readthedocs.io/en/latest/" target="_blank">GraphDot</a>
- <a href="https://xtb-docs.readthedocs.io/en/latest/contents.html" target="_blank">xTB</a>
- <a href="https://wiki.fysik.dtu.dk/ase/index.html" target="_blank">ASE</a>
- scikit-learn
- Numpy
- Matplotlib</p>

<h1 id="conformations-of-polyethylene">Conformations of Polyethylene</h1>

<h2 id="description-of-the-system">Description of the system</h2>

<p>The simple example I chose to explore is learning the energy functional of an ensemble of polyethylene chain conformations. I defined the problem as follows. All chains are made up of 3 monomers — 6 carbon atoms. The rationale for short chains is to keep the degrees of freedom manageable for example purposes. Each chain consists of three C-C-C-C torsion angles and a conformation is defined as a unique set of three torsion angles. I discretized the torsion angle distribution to contain 36 states equally spaced by 10 degrees. The ensemble of conformations is generated by sampling over all of the discrete torsional configurations, so there are ~ 36^3 conformations — some of these are not unique because of symmetry.</p>

<h2 id="description-of-the-active-learning-algorithm">Description of the active learning algorithm</h2>

<p>The objective is to find a surrogate model for calculating the energy of a chain conformation. In general, an energy evaluation with density functional theory (DFT) or another level of quantum chemistry is computationally expensive, so if we can generate a reasonable energy prediction (or predict another property of interest) with a ML model it will save computational time and expand the systems we can study. In this example I generate a graph representation of the different conformations using GraphDot and then use a graph kernel with scikit-learn’s Gaussian Process Regression (GPR) to predict energies. For this simple example we can easily calculate all the energies using xTB; however, if I wanted to use DFT or look at larger systems that would not be possible. As a result, I wanted to implement an active learning strategy. The active learning algorithm I employ is an iterative process where ~1000 conformations are predicted each step, and the 300 most uncertain conformers are fed back into the training data for the next step. This procedure is intended to ensure that the model sees data that will maximally improve the model each step.</p>

<h2 id="imports">Imports</h2>

<pre><code class="language-python">import numpy as np
import pandas as pd
import os
import time
</code></pre>

<pre><code class="language-python">import xtb
from xtb import GFN2

import ase
from ase.io import read, write
from ase.units import Hartree
from ase.optimize import BFGSLineSearch
</code></pre>

<pre><code class="language-python">from graphdot import Graph
from graphdot.graph.adjacency import AtomicAdjacency
from graphdot.kernel.molecular import Tang2019MolecularKernel
from graphdot.kernel.basekernel import KroneckerDelta, SquareExponential, TensorProduct
from graphdot.kernel.marginalized import MarginalizedGraphKernel
</code></pre>

<pre><code class="language-python">#%matplotlib inline
import matplotlib.pyplot as plt
</code></pre>

<pre><code class="language-python">from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
</code></pre>

<h2 id="generate-dataset-via-torsional-configurations">Generate dataset via torsional configurations</h2>

<p>Torsion angles range from 0 to 360 degrees or depending on the convention from -180 to 180 degrees. For the purposes of this demo I am going to use 0 to 360 because it fits naturally with the convention ASE uses.</p>

<pre><code class="language-python">torsion_angles = np.linspace(0.0, 350.0, num=36)
</code></pre>

<pre><code class="language-python">torsion_angles
</code></pre>

<pre><code>array([  0.,  10.,  20.,  30.,  40.,  50.,  60.,  70.,  80.,  90., 100.,
       110., 120., 130., 140., 150., 160., 170., 180., 190., 200., 210.,
       220., 230., 240., 250., 260., 270., 280., 290., 300., 310., 320.,
       330., 340., 350.])
</code></pre>

<p>Generate an array of all combinations for 3 torsion angles ~46,000
this includes all combinations, not all will be unique because of symmetry</p>

<pre><code class="language-python">tor_combinations = np.zeros((46656, 3))
</code></pre>

<pre><code class="language-python">count = 0
for i in torsion_angles:
    for j in torsion_angles:
        for k in torsion_angles:
            tor_combinations[count] = [i, j, k]
            count += 1
</code></pre>

<p>Read in the polyethylene molecule</p>

<pre><code class="language-python">pe_mol = read(&quot;pe_n6.xyz&quot;, format=&quot;xyz&quot;)
</code></pre>

<p>Set the energy calculator</p>

<pre><code class="language-python">pe_mol.set_calculator(GFN2())
</code></pre>

<p>Check how long it takes to calculate the energy</p>

<pre><code class="language-python">%time pe_mol.get_potential_energy()
</code></pre>

<pre><code>CPU times: user 172 ms, sys: 62.1 ms, total: 234 ms
Wall time: 336 ms





-543.9429312223907
</code></pre>

<h2 id="helper-functions-for-generating-data">Helper functions for generating data</h2>

<pre><code class="language-python"># this function randomly selects sets of torsional configurations
# it returns a list of lists, where the sample_num is number of lists and sample len is the length of each list
def random_tor_list(tor_combinations, sample_num, sample_len):
    tor_copy = np.copy(tor_combinations)
    np.random.shuffle(tor_copy)
    tor_lists = []
    for i in range(sample_num):
        j = int(i * sample_len)
        k = int(i * sample_len + sample_len)
        tor_lists.append(tor_copy[j:k])
    return tor_lists
</code></pre>

<pre><code class="language-python"># this function rotates all the torsion angles of the base molecule to the desired angles
def rotate_all_torsions(base_mol, tor_atoms, tor_angles, rot_indices):
    # copy base mol
    rot_mol = base_mol.copy()
    # loop through all the torsion angles in the conformer
    for i, atom in enumerate(tor_atoms):
        rot_mol.set_dihedral(a1=atom[0], a2=atom[1], a3=atom[2], a4=atom[3], 
                             angle=tor_angles[i], indices=rot_indices[i])
    return rot_mol
</code></pre>

<pre><code class="language-python">def generate_graphs(mols, adj):
    graph_list = [Graph.from_ase(mol, adjacency=adj) for mol in mols]
    return graph_list
</code></pre>

<pre><code class="language-python">def generate_data(base_mol, tors_list, tor_atoms, rot_indicies, adj, sample_num):
    mol_list = []
    energy_list = []
    for i, angles in enumerate(tors_list):
        rot_mol = rotate_all_torsions(base_mol, tor_atoms, angles, rot_indicies)
        rot_mol.set_calculator(GFN2())
        energy = rot_mol.get_potential_energy()
        # this if statement limits configurations to under -460.0 eV, so no overlapping atoms/unphysical structures
        # this cutoff includes ~ 90% of the total data 
        if energy &lt; -460.0:
            mol_list.append(rot_mol)
            energy_list.append(energy)
        else:
            continue
        if len(energy_list) == sample_num:
            break
        else:
            continue
    graph_list = generate_graphs(mol_list, adj)
    return graph_list, energy_list
</code></pre>

<h2 id="specify-atoms-involved-in-each-torsion-angle">Specify atoms involved in each torsion angle</h2>

<pre><code class="language-python"># these are specific for this particular molecule and xyz file ordering
pe_n6_tor_atoms = [[0, 1, 5, 8], [1, 5, 8, 11], [5, 8, 11, 14]]
</code></pre>

<pre><code class="language-python"># these are specific for this particular molecule and xyz file ordering
pe_n6_tor_indices=[[8,11,12,13,14,15,16,17,18,19], [11,14,15,16,17,18,19], [14,17,18,19]]
</code></pre>

<h2 id="generate-graphs-and-define-the-graph-kernel">Generate graphs and define the graph kernel</h2>

<pre><code class="language-python">adj = AtomicAdjacency(shape='tent2', zoom=2.0)
</code></pre>

<p>def generate_graphs(mols, adj):
    graph_list = []
    for mol in mols:
        graph = Graph.from_ase(mol, adjacency=adj)
        graph_list.append(graph)
    return graph_listdef generate_graphs(mols, adj):
    graph_list = [Graph.from_ase(mol, adjacency=adj) for mol in mols]
    return graph_list</p>

<pre><code class="language-python">mol_kernel = Tang2019MolecularKernel(edge_length_scale=0.04, stopping_probability=0.01)
</code></pre>

<p>In order to use scikit-learn GPR we need to to define a MarginalizedGraphKernel object. The kernel defined below is essentiually the same as the Tang2019MolecularKernel.</p>

<pre><code class="language-python">kernel = MarginalizedGraphKernel(node_kernel=TensorProduct(element=KroneckerDelta(0.2)), 
                                 edge_kernel=TensorProduct(length=SquareExponential(0.04)), 
                                 q=0.01)
</code></pre>

<h2 id="check-graphs-and-visualize-similarity-matrix">Check graphs and visualize similarity matrix</h2>

<pre><code class="language-python">try_tors = random_tor_list(tor_combinations, 1, 700)
</code></pre>

<pre><code class="language-python">try_graphs, try_energies = generate_data(pe_mol, try_tors[0], pe_n6_tor_atoms, pe_n6_tor_indices, adj, 500)
</code></pre>

<pre><code class="language-python">len(try_graphs), len(try_energies)
</code></pre>

<pre><code>(500, 500)
</code></pre>

<pre><code class="language-python">R_mol = mol_kernel(try_graphs, lmin=1).astype(np.float)
</code></pre>

<pre><code class="language-python">D_mol = R_mol.diagonal()**-0.5
</code></pre>

<pre><code class="language-python">K_mol = D_mol[:, None] * R_mol * D_mol[None, :]
</code></pre>

<pre><code class="language-python">plt.imshow(K_mol)
</code></pre>

<pre><code>&lt;matplotlib.image.AxesImage at 0x2aaad685ef50&gt;
</code></pre>

<p><img src="./active_learning_demo_2_51_1.png" alt="png" /></p>

<pre><code class="language-python">K_mol.max()
</code></pre>

<pre><code>1.0000000000000002
</code></pre>

<pre><code class="language-python">K_mol.min()
</code></pre>

<pre><code>0.8540028342871165
</code></pre>

<pre><code class="language-python">R = kernel(try_graphs, lmin=1).astype(np.float)
</code></pre>

<pre><code class="language-python">D = R.diagonal()**-0.5
</code></pre>

<pre><code class="language-python">K = D[:, None] * R * D[None, :]
</code></pre>

<pre><code class="language-python">plt.imshow(K)
</code></pre>

<pre><code>&lt;matplotlib.image.AxesImage at 0x2aab1e472fd0&gt;
</code></pre>

<p><img src="./active_learning_demo_2_57_1.png" alt="png" /></p>

<pre><code class="language-python">K.max()
</code></pre>

<pre><code>1.0000000000000002
</code></pre>

<pre><code class="language-python">K.min()
</code></pre>

<pre><code>0.8540028342871165
</code></pre>

<h2 id="active-learning-class">Active learning class</h2>

<pre><code class="language-python">class active_gpr():
    def __init__(self, kernel, X_train, y_train, X_test, y_test):
        self.X_train = X_train
        self.y_train = y_train
        self.X_test = X_test
        self.y_test = y_test
        self.uncertain = None
        self.gpr = GaussianProcessRegressor(kernel=kernel, optimizer=None, alpha=0.015, normalize_y=True)
        self.metrics = {&quot;step&quot;: [], &quot;rmse&quot;: [], &quot;mae&quot;: [], &quot;r2&quot;: []}
        self.step = 0
        
    def train(self):
        self.gpr.fit(self.X_train, self.y_train)
        y_pred = self.gpr.predict(self.X_test)
        r2 = r2_score(self.y_test, y_pred)
        rmse = mean_squared_error(self.y_test, y_pred, squared=False) 
        mae = mean_absolute_error(self.y_test, y_pred)
        self.metrics[&quot;step&quot;].append(self.step)
        self.metrics[&quot;rmse&quot;].append(rmse)
        self.metrics[&quot;mae&quot;].append(mae)
        self.metrics[&quot;r2&quot;].append(r2)
        self.step += 1
    
    def predict(self, X_new, sample_num=300):
        y_pred, y_std = self.gpr.predict(X_new, return_std=True)
        # np.argsort sorts from min to max so selecting from the end of array gives the
        # the max uncertainty
        uncertain_indexes = np.argsort(y_std)
        self.uncertain = uncertain_indexes[(len(uncertain_indexes) - sample_num):]

    def update_data(self, X, y):
        X_new = np.array(X)[self.uncertain]
        y_new = np.array(y)[self.uncertain]
        X_train = np.concatenate((self.X_train, X_new), axis=0)
        y_train = np.concatenate((self.y_train, y_new), axis=0)
        # shuffle data
        shuffle_ind = np.arange(len(X_train))
        np.random.shuffle(shuffle_ind)
        self.X_train = X_train[shuffle_ind]
        self.y_train = y_train[shuffle_ind]
</code></pre>

<h2 id="active-learning-loop">Active learning loop</h2>

<pre><code class="language-python"># define train and test torsion sets
</code></pre>

<pre><code class="language-python">def train_test_split(tor_combinations, test_size):
    tor_copy = np.copy(tor_combinations)
    np.random.shuffle(tor_copy)
    # returns the train set and test set
    train_set = tor_copy[test_size:]
    test_set = tor_copy[:test_size]
    return train_set, test_set
</code></pre>

<pre><code class="language-python"># test set size will be 3000 but the energy cutoff will remove ~ 10% of data
</code></pre>

<pre><code class="language-python">train_tor_set, test_tor_set = train_test_split(tor_combinations, test_size=4000)
</code></pre>

<pre><code class="language-python">train_tor_list = random_tor_list(train_tor_set, 11, 1500)
</code></pre>

<pre><code class="language-python">X_train_init, y_train_init = generate_data(pe_mol, train_tor_list[0], pe_n6_tor_atoms, pe_n6_tor_indices, adj, 1000)
</code></pre>

<pre><code class="language-python">X_test, y_test = generate_data(pe_mol, test_tor_set, pe_n6_tor_atoms, pe_n6_tor_indices, adj, 3000)
</code></pre>

<pre><code class="language-python">pe_gpr = active_gpr(kernel, X_train_init, y_train_init, X_test, y_test)
</code></pre>

<pre><code class="language-python">active_steps = range(0, 10)
for step in active_steps:
    s_time = time.perf_counter()
    print(&quot;Learning Step: {s}&quot;.format(s=pe_gpr.step))
    print(&quot;Training Data Size: {d}&quot;.format(d=len(pe_gpr.X_train)))
    
    pe_gpr.train()
    X_new, y_new = generate_data(pe_mol, train_tor_list[step + 1], pe_n6_tor_atoms, pe_n6_tor_indices, adj, 1000) 
    pe_gpr.predict(X_new)
    pe_gpr.update_data(X_new, y_new)
    e_time = time.perf_counter()
    
    print(&quot;MAE: {mae:0.3f}&quot;.format(mae=pe_gpr.metrics[&quot;mae&quot;][step]))
    print(&quot;RMSE: {rmse:0.3f}&quot;.format(rmse=pe_gpr.metrics[&quot;rmse&quot;][step]))
    print(&quot;R-squared: {r2:0.5f}&quot;.format(r2=pe_gpr.metrics[&quot;r2&quot;][step]))
    print(&quot;Step Time(s): {t:0.2f}&quot;.format(t=(e_time - s_time)))
    print(&quot;---------- End of Step ----------&quot;)
</code></pre>

<pre><code>Learning Step: 0
Training Data Size: 1000
      0.5 ms on generating jobs
      0.2 ms on creating output buffer
     14.8 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
     19.0 ms on code generation
    156.0 ms on JIT
      2.8 ms on calculating launch configuration
      5.1 ms on GPU kernel execution
    198.2 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
MAE: 0.933
RMSE: 1.602
R-squared: 0.99464
Step Time(s): 50.14
---------- End of Step ----------
Learning Step: 1
Training Data Size: 1300
      0.5 ms on generating jobs
      0.3 ms on creating output buffer
     14.1 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
      9.1 ms on code generation
    161.1 ms on JIT
      2.4 ms on calculating launch configuration
      5.2 ms on GPU kernel execution
    192.5 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
MAE: 0.742
RMSE: 1.102
R-squared: 0.99747
Step Time(s): 49.42
---------- End of Step ----------
Learning Step: 2
Training Data Size: 1600
      0.5 ms on generating jobs
      0.3 ms on creating output buffer
     13.7 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
      8.7 ms on code generation
    162.7 ms on JIT
      2.5 ms on calculating launch configuration
      5.4 ms on GPU kernel execution
    193.6 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
MAE: 0.637
RMSE: 0.953
R-squared: 0.99810
Step Time(s): 56.18
---------- End of Step ----------
Learning Step: 3
Training Data Size: 1900
      0.5 ms on generating jobs
      0.3 ms on creating output buffer
     14.2 ms on transferring graphs to GPU
      0.2 ms on allocate global job counter
      8.8 ms on code generation
    158.5 ms on JIT
      2.6 ms on calculating launch configuration
      5.3 ms on GPU kernel execution
    189.9 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
MAE: 0.578
RMSE: 0.864
R-squared: 0.99844
Step Time(s): 64.12
---------- End of Step ----------
Learning Step: 4
Training Data Size: 2200
      0.7 ms on generating jobs
      0.2 ms on creating output buffer
     19.0 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
     13.1 ms on code generation
    156.0 ms on JIT
      2.8 ms on calculating launch configuration
      5.3 ms on GPU kernel execution
    196.8 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
MAE: 0.519
RMSE: 0.794
R-squared: 0.99868
Step Time(s): 72.42
---------- End of Step ----------
Learning Step: 5
Training Data Size: 2500
      0.6 ms on generating jobs
      0.3 ms on creating output buffer
     17.8 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
     10.2 ms on code generation
    149.2 ms on JIT
      2.8 ms on calculating launch configuration
      5.1 ms on GPU kernel execution
    185.5 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
MAE: 0.486
RMSE: 0.666
R-squared: 0.99907
Step Time(s): 81.97
---------- End of Step ----------
Learning Step: 6
Training Data Size: 2800
      0.5 ms on generating jobs
      0.2 ms on creating output buffer
     14.4 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
      8.9 ms on code generation
    144.5 ms on JIT
      2.6 ms on calculating launch configuration
      4.9 ms on GPU kernel execution
    175.8 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
MAE: 0.455
RMSE: 0.620
R-squared: 0.99920
Step Time(s): 92.25
---------- End of Step ----------
Learning Step: 7
Training Data Size: 3100
      0.5 ms on generating jobs
      0.2 ms on creating output buffer
     14.3 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
      8.8 ms on code generation
    144.6 ms on JIT
      2.2 ms on calculating launch configuration
      4.8 ms on GPU kernel execution
    175.3 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
MAE: 0.441
RMSE: 0.586
R-squared: 0.99928
Step Time(s): 103.26
---------- End of Step ----------
Learning Step: 8
Training Data Size: 3400
      0.6 ms on generating jobs
      0.3 ms on creating output buffer
     18.5 ms on transferring graphs to GPU
      0.2 ms on allocate global job counter
     10.3 ms on code generation
    141.6 ms on JIT
      2.5 ms on calculating launch configuration
      4.9 ms on GPU kernel execution
    178.3 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
MAE: 0.415
RMSE: 0.567
R-squared: 0.99933
Step Time(s): 114.71
---------- End of Step ----------
Learning Step: 9
Training Data Size: 3700
      0.6 ms on generating jobs
      0.2 ms on creating output buffer
     14.6 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
      9.1 ms on code generation
    134.6 ms on JIT
      3.1 ms on calculating launch configuration
      4.9 ms on GPU kernel execution
    166.7 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
MAE: 0.415
RMSE: 0.552
R-squared: 0.99936
Step Time(s): 125.99
---------- End of Step ----------
</code></pre>

<h2 id="plot-mae-and-rmse">Plot MAE and RMSE</h2>

<pre><code class="language-python">fig = plt.figure()
ax = plt.subplot(111)
ax.plot(range(1,11), pe_gpr.metrics[&quot;mae&quot;])
ax.set_xlabel('Active Learing Step', fontsize=15)
ax.set_ylabel('MAE\n(eV)', rotation=0, labelpad=30, fontsize=15)
#ax.set_ylim(0.00, 0.14)
ax.spines['right'].set_visible(False)
ax.spines['top'].set_visible(False)
#plt.title(&quot;&quot;, fontsize=15)
#ax.legend([], frameon=False)
</code></pre>

<p><img src="./active_learning_demo_2_73_0.png" alt="png" /></p>

<pre><code class="language-python">fig = plt.figure()
ax = plt.subplot(111)
ax.plot(range(1,11), pe_gpr.metrics[&quot;rmse&quot;], color=&quot;orange&quot;)
ax.set_xlabel('Learing Step', fontsize=15)
ax.set_ylabel('RMSE\n(eV)', rotation=0, labelpad=30, fontsize=15)
#ax.set_ylim(0.00, 0.14)
ax.spines['right'].set_visible(False)
ax.spines['top'].set_visible(False)
#plt.title(&quot;&quot;, fontsize=15)
#ax.legend([], frameon=False)
</code></pre>

<p><img src="./active_learning_demo_2_74_0.png" alt="png" /></p>

    </div>

    




    



  







    
    

    

    


  </div>
</article>

<div class="container">
  <footer class="site-footer">
  

  <p class="powered-by">
    &copy; 2020 Brandon Wood &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

</div>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha512-+NqPlbbtM1QqiK8ZAo4Yrj2c4lNQoGv8P79DPtKzj++l5jnN39rHA/xsqn8zE9l0uSoxaCdrOgFs6yjyfbBxSg==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha256-VsEqElsCHSGmnmHXGQzvoWjWwoznFSZc6hs7ARLRacQ=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
        
      

      
      
    

    
    

    
    
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "results found",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    
    
    
    
    
    
    
    <script src="/js/academic.min.d037ee5294b166a79dec317c58aea9cc.js"></script>

    

  </body>
</html>

