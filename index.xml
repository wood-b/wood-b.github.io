<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title></title>
    <link>https://wood-b.github.io/</link>
    <description>Recent content on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2020 Brandon Wood</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 -0500</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>A Novice’s Guide to Hyperparameter Optimization at Scale</title>
      <link>https://wood-b.github.io/post/a-novices-guide-to-hyperparameter-optimization-at-scale/</link>
      <pubDate>Sun, 30 Aug 2020 23:08:53 -0500</pubDate>
      
      <guid>https://wood-b.github.io/post/a-novices-guide-to-hyperparameter-optimization-at-scale/</guid>
      <description>

&lt;p&gt;&lt;strong&gt;TL;DR:&lt;/strong&gt; Running HPO at scale is important and &lt;a href=&#34;https://docs.ray.io/en/latest/tune/index.html&#34; target=&#34;_blank&#34;&gt;Ray Tune&lt;/a&gt; makes that easy. When considering what HPO strategies to use for your project, start by choosing a scheduler — it can massively improve performance — with random search and build complexity as needed. When in doubt, ASHA is a good default scheduler.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Acknowledgements:&lt;/strong&gt;
I want to thank &lt;a href=&#34;https://ulissigroup.cheme.cmu.edu&#34; target=&#34;_blank&#34;&gt;Zachary Ulissi&lt;/a&gt; (CMU), &lt;a href=&#34;https://www.nersc.gov/about/nersc-staff/data-analytics-services/mustafa-mustafa/&#34; target=&#34;_blank&#34;&gt;Mustafa Mustafa&lt;/a&gt; (NERSC), and &lt;a href=&#34;https://github.com/richardliaw&#34; target=&#34;_blank&#34;&gt;Richard Liaw&lt;/a&gt; (Ray Tune) for making this work possible.&lt;/p&gt;

&lt;h2 id=&#34;table-of-contents&#34;&gt;Table of Contents:&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#scalable-hpo-with-ray-tune&#34;&gt;Scalable HPO with Ray Tune&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#how-to-select-an-hpo-strategy&#34;&gt;How to Select an HPO Strategy&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#schedulers-vs-search-algorithms&#34;&gt;Schedulers vs Search Algorithms&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#time-to-solution-study&#34;&gt;Time-to-Solution Study&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#not-all-hyperparameters-can-be-treated-the-same&#34;&gt;Not all Hyperparameters Can Be Treated the Same&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#optimal-scheduling-with-pbt&#34;&gt;Optimal Scheduling with PBT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#cheat-sheet-for-selecting-an-hpo-strategy&#34;&gt;Cheat Sheet for Selecting an HPO Strategy&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#technical-tips&#34;&gt;Technical Tips&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#ray-tune&#34;&gt;Ray Tune&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#dragonfly&#34;&gt;Dragonfly&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#slurm&#34;&gt;Slurm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#tensorboard&#34;&gt;TensorBoard&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#weights-and-biases&#34;&gt;Weights and Biases&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#key-findings&#34;&gt;Key Findings&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#key-takeaways&#34;&gt;Key Takeaways&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Despite the tremendous success of machine learning (ML), modern algorithms still depend on a variety of free non-trainable hyperparameters. Ultimately, our ability to select quality hyperparameters governs the performance for a given model.  In the past, and even some currently, hyperparameters were hand selected through trial and error. An entire field has been dedicated to improving this selection process; it is referred to as hyperparameter optimization (HPO). Inherently, HPO requires testing many different hyperparameter configurations and as a result can benefit tremendously from massively parallel resources like the &lt;a href=&#34;https://www.nersc.gov/systems/perlmutter/&#34; target=&#34;_blank&#34;&gt;Perlmutter system&lt;/a&gt; we are building at the National Energy Research Scientific Computing Center (&lt;a href=&#34;https://www.nersc.gov&#34; target=&#34;_blank&#34;&gt;NERSC&lt;/a&gt;). As we prepare for Perlmutter, we wanted to explore the multitude of HPO frameworks and strategies that exist on a model of interest. This article is a product of that exploration and is intended to provide an introduction to HPO methods and guidance on running HPO at scale based on my recent experiences and results.&lt;/p&gt;

&lt;p&gt;Disclaimer; this article contains plenty of general non-software specific information about HPO, but there is a bias for free open source software that is applicable to our systems at NERSC.&lt;/p&gt;

&lt;h2 id=&#34;scalable-hpo-with-ray-tune&#34;&gt;Scalable HPO with Ray Tune&lt;/h2&gt;

&lt;p&gt;Being able to leverage the power of modern compute resources to run HPO at scale is important to efficiently search hyperparameter space — especially in the time of deep learning (DL) where the size of neural networks continues to increase. Luckily for all of us, the folks at &lt;a href=&#34;https://docs.ray.io/en/latest/tune/index.html&#34; target=&#34;_blank&#34;&gt;Ray Tune&lt;/a&gt; have made scalable HPO easy. Below is a graphic of the general procedure to run Ray Tune at NERSC. &lt;a href=&#34;https://docs.ray.io/en/latest/tune/index.html&#34; target=&#34;_blank&#34;&gt;Ray Tune&lt;/a&gt; is an open-source python library for distributed HPO built on Ray. Some highlights of Ray Tune:
- Supports any ML framework
- Internally handles job scheduling based on the resources available
- Integrates with external optimization packages (e.g. Ax, Dragonfly, HyperOpt, SigOpt)
- Implements state-of-the-art schedulers (e.g. ASHA, AHB, PBT)&lt;/p&gt;

&lt;p&gt;I have enjoyed using &lt;a href=&#34;https://docs.ray.io/en/latest/tune/index.html&#34; target=&#34;_blank&#34;&gt;Ray Tune&lt;/a&gt;, but if you choose a different HPO framework, no worries, there is still plenty of general information in this article.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;tune_flow.png&#34; alt=&#34;tune&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;how-to-select-an-hpo-strategy&#34;&gt;How to Select an HPO strategy&lt;/h2&gt;

&lt;h3 id=&#34;schedulers-vs-search-algorithms&#34;&gt;Schedulers vs Search Algorithms&lt;/h3&gt;

&lt;p&gt;One of the first distinctions I want to point out about HPO strategies, is the difference between a scheduler and a search algorithm. The search algorithm governs how hyperparameter space is sampled and optimized (e.g. random search). From a practical standpoint, the search algorithm provides a mechanism to select hyperparameter configurations (i.e. trials) to test. A search algorithm is always necessary for HPO. Alternatively, schedulers improve the overall efficiency of the HPO by terminating unpromising trials early. For example, if I use random search, some of the trials are expected to perform poorly, so it would be nice to have the ability to terminate those trials early — saving valuable compute resources. This is what a scheduler does. A scheduler is not necessary for HPO but they massively improve performance. Below are brief descriptions and references for the schedulers and the search algorithms I tested.&lt;/p&gt;

&lt;h4 id=&#34;async-successive-halving-algorithm-asha-scheduler&#34;&gt;Async Successive Halving Algorithm (ASHA — scheduler)&lt;/h4&gt;

&lt;p&gt;First, I want to define the successive halving algorithm (SHA), and instead of doing it myself, I really like the definition given in this &lt;a href=&#34;https://arxiv.org/pdf/1810.05934.pdf&#34; target=&#34;_blank&#34;&gt;paper&lt;/a&gt; — they also have pseudocode of the SHA and ASHA, if you are interested.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The idea behind SHA is simple: allocate a small budget to each configuration, evaluate all configurations and keep the top 1/η, increase the budget per configuration by a factor of η, and repeat until the maximum per-configuration budget of R is reached.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;sha.gif&#34; alt=&#34;sha&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This graphic was adapted from an AutoML &lt;a href=&#34;https://www.automl.org/blog_bohb/&#34; target=&#34;_blank&#34;&gt;post&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The SHA does not parallelize well because all configurations need to be evaluated for a short time before the top 1/η can be selected. This creates a bottleneck at each rung (each successive halving is referred to as a rung). ASHA decouples trial promotion and rung completion, such that trials can be advanced to the next rung at any given time. If a trial cannot be promoted additional trials can be added to the base rung so more promotions are possible.&lt;/p&gt;

&lt;p&gt;A major assumption of SHA and ASHA is that if a trial performs well over an initial short time interval it will perform well at longer time intervals. A classic example where this assumption can break down is tuning learning rates. Larger learning rates may outperform smaller learning rates at short times causing the smaller learning rate trials to be erroneously terminated. In practice, I am honestly not sure how much this matters.&lt;/p&gt;

&lt;h4 id=&#34;async-hyperband-ahb-scheduler&#34;&gt;Async Hyperband (AHB — scheduler)&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/1603.06560.pdf&#34; target=&#34;_blank&#34;&gt;Hyperband&lt;/a&gt; (HB) is a scheduler designed to mitigate the SHA&amp;rsquo;s bias towards initial performance. HB essentially loops over the SHA with a variety of halving rates — attempting to balance early termination with providing more resources per trial regardless of initial performance. Each loop of the SHA is considered a bracket, which can have a number of rungs. See the figure below. AHB is identical to HB except it loops over ASHA. The AHB and ASHA implementation used in Ray Tune is described in this &lt;a href=&#34;https://arxiv.org/pdf/1810.05934.pdf&#34; target=&#34;_blank&#34;&gt;paper&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;hb_ladder.png&#34; alt=&#34;hb&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;population-based-training-pbt-hybrid&#34;&gt;Population Based Training (PBT — hybrid)&lt;/h4&gt;

&lt;p&gt;I call PBT a hybrid because it has aspects of both a scheduler and a search algorithm. It can also function as an HPO strategy and a trainer all-in-one. More on that in the Not all Hyperparameters Are the Same section. At a high-level, PBT is similar to a genetic algorithm. There is a population of workers, where each worker is assigned a random configuration of hyperparameters (trial) and at set intervals hyperparameter configurations are replaced by higher performing workers in the population (exploitation) and randomly perturbed (exploration). The user can set the balance of exploitation vs exploration. Here are a couple resources to learn more, &lt;a href=&#34;https://deepmind.com/blog/article/population-based-training-neural-networks&#34; target=&#34;_blank&#34;&gt;blog&lt;/a&gt; and &lt;a href=&#34;https://arxiv.org/pdf/1711.09846.pdf&#34; target=&#34;_blank&#34;&gt;paper&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;pbt_example.png&#34; alt=&#34;pbt&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;random-search-rs-search-algorithm&#34;&gt;Random Search (RS — search algorithm)&lt;/h4&gt;

&lt;p&gt;When the hyperparameter space of interest is reasonably large, too large for a grid search, the default algorithm is random search. This is exactly as it sounds, hyperparameter configurations or trials are randomly selected from the search space. If given enough compute time RS works reasonably well.&lt;/p&gt;

&lt;h4 id=&#34;bayesian-optimization-bo-search-algorithm&#34;&gt;Bayesian Optimization (BO — search algorithm)&lt;/h4&gt;

&lt;p&gt;BO provides an algorithmic approach to determining the optimal hyperparameters, instead of randomly searching. Because the objective function is unknown in HPO a black-box optimizer like BO is necessary. In BO a surrogate models the objective function and an acquisition function is used for sampling new points or new hyperparameter configurations in this case. Gaussian processes are typically used as the surrogate models in BO for HPO. Ideally, BO can converge towards the optimal hyperparameters much more efficiently than random search.&lt;/p&gt;

&lt;h3 id=&#34;time-to-solution-study&#34;&gt;Time-to-Solution Study&lt;/h3&gt;

&lt;p&gt;To compare different HPO strategies I decided to keep it simple and focus on the average time-to-solution, which is a metric that is relatively straightforward to interpret. There are a couple caveats for my results:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;I did this work with a particular model and problem in mind (more on that below), so I do not expect these results to be completely general.&lt;/li&gt;
&lt;li&gt;There are many arbitrary choices that go into various HPO strategies that may alter the results.&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;model-details&#34;&gt;Model details&lt;/h4&gt;

&lt;p&gt;The model I was interested in optimizing hyperparameters for is a graph neural network used in the field of catalysis to predict adsorption energies. Specific details can be found &lt;a href=&#34;https://doi.org/10.1021/acs.jpclett.9b01428&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&#34;hyperparameters&#34;&gt;Hyperparameters&lt;/h4&gt;

&lt;p&gt;There were six hyperparameters I examined and they are listed below:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Learning Rate&lt;/li&gt;
&lt;li&gt;Batch Size&lt;/li&gt;
&lt;li&gt;Atom Embedding Size&lt;/li&gt;
&lt;li&gt;Number of Graph Convolution Layers&lt;/li&gt;
&lt;li&gt;Fully Connected Feature Size&lt;/li&gt;
&lt;li&gt;Number of Fully Connected Layers&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Pro Tip:&lt;/strong&gt; When making decisions about the size of the hyperparameter space you want to search — consider memory usage. When tuning network architecture and batch size I ran into memory issues on our 16GB GPUs at NERSC.&lt;/p&gt;

&lt;h4 id=&#34;questions-explored&#34;&gt;Questions Explored&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;What is the impact of a scheduler?&lt;/li&gt;
&lt;li&gt;How much can a sophisticated search algorithm improve HPO?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The first question I wanted to investigate was the impact of using a scheduler. To address this question I compared the time-to-solution of ASHA/RS, AHB/RS, and RS using the same computational resources for each (4 Cori GPU Nodes for 8 hours). All three strategies use the same search algorithm with the addition of the ASHA and the AHB schedulers. The notation I am using is scheduler/search algorithm.&lt;/p&gt;

&lt;p&gt;Going beyond a scheduler, I was curious how much a &amp;ldquo;smarter&amp;rdquo; search algorithm, such as BO, would improve HPO performance. To explore this question I compared the time-to-solution of ASHA/RS and ASHA/BO using the same computational resources for each (4 Cori GPU Nodes for 4 hours).&lt;/p&gt;

&lt;h4 id=&#34;results-and-discussion&#34;&gt;Results and Discussion&lt;/h4&gt;

&lt;h5 id=&#34;average-time-to-solution-plot-comparing-asha-rs-ahb-rs-and-rs-given-the-same-computational-resources&#34;&gt;Average time-to-solution plot comparing ASHA/RS, AHB/RS, and RS given the same computational resources&lt;/h5&gt;

&lt;p&gt;&lt;img src=&#34;hpo_8hr_compare_asha_ahb_rs_std_abrev.png&#34; alt=&#34;fig1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ASHA/RS clearly outperformed both AHB/RS and RS by reaching a lower average test MAE in a shorter period of time. ASHA/RS improved the time-to-solution by at least 5x compared to RS. I say at least 5x, because RS did not converge to the lower limit of the test MAE in the 8 hour limit. Additionally, more ASHA/RS trials were close to the mean resulting in a smaller standard deviation. The top 6 trials were time averaged in all cases. I suspect the performance of ASHA/RS is largely because of the number of trials completed. ASHA/RS finished nearly 2x the trials of AHB/RS and over 8x the trials of RS. The number of trials finished can be seen in the top right corner. I should also mention that the number of ASHA/RS and AHB/RS trials are not at their upper limit because of the amount of checkpoint I was doing. &lt;strong&gt;Minimal checkpointing is critical for the performance of SHA based HPO strategies.&lt;/strong&gt; This is illustrated by the number of trials finished in the ASHA/RS experiment below that used less checkpointing — the same amount of trials in half the time. The reduced checkpointing increased the time-to-solution improvement for ASHA/RS to approximately 10x compared to RS!&lt;/p&gt;

&lt;h5 id=&#34;average-time-to-solution-plot-comparing-asha-rs-and-asha-bo-given-the-same-computational-resources&#34;&gt;Average time-to-solution plot comparing ASHA/RS and ASHA/BO given the same computational resources&lt;/h5&gt;

&lt;p&gt;&lt;img src=&#34;hpo_4hr_compare_asha_rs_asha_bo_std.png&#34; alt=&#34;fig2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;It can be seen from the figure above that there is on average no benefit to adding BO for my particular model. My hypothesis is that the hyperparameter surface I was trying to optimize had a bunch of local minima (think egg carton) and no obvious global minimum, which would reduce the benefit of BO. Situations where I can see BO working well are large hyperparameter search spaces with a more well defined global minimum — not that you can know this &lt;em&gt;a priori&lt;/em&gt;. Overall, I think a good approach to HPO is building complexity as needed. One last note on BO, while there was not an average improvement using BO the single best trial I found was using ASHA/BO. As a result, if I had to choose one configuration of hyperparameters that is what I would select.&lt;/p&gt;

&lt;p&gt;The time delay between the ASHA/RS and the ASHA/BO curves is likely because the acquisition function used in BO needs to be conditioned with a certain amount of data before sampling new hyperparameter configurations.&lt;/p&gt;

&lt;h3 id=&#34;not-all-hyperparameters-can-be-treated-the-same&#34;&gt;Not all Hyperparameters Can Be Treated the Same&lt;/h3&gt;

&lt;p&gt;There are two main types of hyperparameters in ML and they dictate what HPO strategies are possible.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Model Hyperparameters:&lt;/strong&gt; Establish model architecture&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Number of convolutional layers&lt;/li&gt;
&lt;li&gt;Number of fully connected layers&lt;/li&gt;
&lt;li&gt;etc.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Algorithm Hyperparameters:&lt;/strong&gt; Are involved in the learning process&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Learning rates&lt;/li&gt;
&lt;li&gt;Batch size&lt;/li&gt;
&lt;li&gt;Momentum&lt;/li&gt;
&lt;li&gt;etc.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The important takeaway is that not all HPO strategies can handle both model and algorithm hyperparameters. PBT is a good example. PBT was designed to evolve and inherit hyperparameters from other high performing workers in the population; however, if workers have different network architectures it is unclear to me how exactly that would work. There might be a way to do this with PBT, but it is not standard and does not work out-of-the-box with Ray Tune.&lt;/p&gt;

&lt;h3 id=&#34;optimal-scheduling-with-pbt&#34;&gt;Optimal Scheduling with PBT&lt;/h3&gt;

&lt;p&gt;One of the nice features of PBT is the ability to develop an ideal scheduling procedure. For instance, I can determine the ideal learning rate throughout training, which is usually quite important. In my case, I want a configuration of hyperparameters and a learning rate scheduler that I can use to train my model repeatedly. Most ML frameworks include learning rate schedulers (e.g. multistep, reduce on plateau, exponential decay, etc.) to reduce the learning rate as training progresses. Hence, a custom learning rate scheduler can be developed using PBT and incorporated into a given ML framework for subsequent training.&lt;/p&gt;

&lt;p&gt;Alternatively, if repeated training is not necessary for your application PBT can be used directly as a training procedure and ideal schedules can be developed for all algorithm hyperparameters simultaneously.&lt;/p&gt;

&lt;p&gt;Training with PBT is very efficient in terms of actual time, in fact it uses roughly the same amount of time as your normal training procedure, but total computational time goes up because multiple workers are necessary — maybe 16 - 32 GPUs. In Ray Tune, workers can also be time-multiplexed if the number of workers exceeds the resource size.&lt;/p&gt;

&lt;h4 id=&#34;optimal-learning-rate-results-and-discussion&#34;&gt;Optimal Learning Rate — Results and Discussion&lt;/h4&gt;

&lt;p&gt;I wanted to experiment with PBT and find a learning rate schedule for my model (described above). Here are the results.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;pbt_best_trial_lr.png&#34; alt=&#34;pbt&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The top plot shows the Test MAE for the best trial in the population. There are some jumps in the Test MAE where presumably random perturbations were attempted and since there was not an improvement the perturbations were ultimately reversed. The lower plot displays the learning rate as a function of training iterations. It appears that my ideal learning rate could reasonably be modeled by a multistep scheduler.&lt;/p&gt;

&lt;h3 id=&#34;cheat-sheet-for-selecting-an-hpo-strategy&#34;&gt;Cheat Sheet for Selecting an HPO Strategy&lt;/h3&gt;

&lt;p&gt;Choosing an HPO strategy really depends on your particular application. For many of the chemistry and materials science applications that I am interested in, reasonably good hyperparameters that get us 85% of the way there will do just fine. Alternatively, some of you might be interested in squeezing out every last drop of performance for a given model. There is not a one-size-fits-all solution, but I&amp;rsquo;ve put together a little cheat sheet to help get the ideas flowing.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;hpo_cheat_sheet.png&#34; alt=&#34;cheat_sheet&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;technical-tips&#34;&gt;Technical Tips&lt;/h2&gt;

&lt;h3 id=&#34;ray-tune&#34;&gt;Ray Tune&lt;/h3&gt;

&lt;p&gt;Ray Tune is very user friendly and you only need to consider a few things when setting it up to run your model (I am not going to go in-depth here because Ray Tune&amp;rsquo;s &lt;a href=&#34;https://docs.ray.io/en/latest/tune/index.html&#34; target=&#34;_blank&#34;&gt;documentation&lt;/a&gt; and &lt;a href=&#34;https://github.com/ray-project/ray/tree/master/python/ray/tune/examples&#34; target=&#34;_blank&#34;&gt;examples&lt;/a&gt; are great):
1. Define a trainable API, either function or class based — I recommend the class option as it allows you do much more
2. Write a script to run Tune via &lt;code&gt;tune.run()&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;general-tips&#34;&gt;General Tips&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Check to ensure your model is being put on the right device, this sounds silly but it&amp;rsquo;s worthwhile. Put a print statement in your &lt;code&gt;_setup&lt;/code&gt; function, if you are using the class API, to double check&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Ray Tune has a bunch of handy &lt;a href=&#34;https://docs.ray.io/en/master/tune/api_docs/grid_random.html#custom-conditional-search-spaces&#34; target=&#34;_blank&#34;&gt;functions&lt;/a&gt; (e.g. &lt;code&gt;tune.uniform&lt;/code&gt;) to generate random distributions&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;tune-run-flags-for-performance&#34;&gt;&lt;code&gt;Tune.run()&lt;/code&gt; Flags for Performance&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;checkpoint_at_end=False&lt;/code&gt; Default is False and I would leave it that way regardless of other checkpointing settings. True, should never be used with SHA based strategies&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sync_on_checkpoint=False&lt;/code&gt; This can improve performance but maybe only marginally — it depends on how frequently you are checkpointing&lt;/li&gt;
&lt;li&gt;&lt;code&gt;fail_fast=True&lt;/code&gt; I like this flag because it kills a trial immediately after it fails, otherwise the trial can go through all training iterations where it fails each iteration&lt;/li&gt;
&lt;li&gt;&lt;code&gt;reuse_actors=True&lt;/code&gt; This flag can improve performance on both ASHA and PBT but it requires you to add a &lt;code&gt;reset_config&lt;/code&gt; function to your trainable class. In part, this flag can save time by not reloading your dataset everytime an old trial is terminated and a new trial begins.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;dragonfly-bo&#34;&gt;Dragonfly — BO&lt;/h3&gt;

&lt;p&gt;I like &lt;a href=&#34;https://github.com/dragonfly/dragonfly&#34; target=&#34;_blank&#34;&gt;Dragonfly&lt;/a&gt; for Bayesian Optimization because of its ability to work with both discrete and continuous variables. Many BO packages only work with continuous variables and you have to hack your way around that issue. Nevertheless, I did find it a bit tricky to actually define the hyperparameter space. Below is the code snippet I used to set up Dragonfly BO for use with Ray Tune.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;param_list = [{&amp;quot;name&amp;quot;: &amp;quot;atom_embedding_size&amp;quot;,
                &amp;quot;type&amp;quot;: &amp;quot;int&amp;quot;,
                &amp;quot;min&amp;quot;: 1,
                &amp;quot;max&amp;quot;: 100},
              {&amp;quot;name&amp;quot;: &amp;quot;num_graph_conv_layers&amp;quot;,
                &amp;quot;type&amp;quot;: &amp;quot;int&amp;quot;,
                &amp;quot;min&amp;quot;: 1,
                &amp;quot;max&amp;quot;: 40},
              {&amp;quot;name&amp;quot;: &amp;quot;fc_feat_size&amp;quot;,
                &amp;quot;type&amp;quot;: &amp;quot;int&amp;quot;,
                &amp;quot;min&amp;quot;: 1,
                &amp;quot;max&amp;quot;: 150},
              {&amp;quot;name&amp;quot;: &amp;quot;num_fc_layers&amp;quot;,
                &amp;quot;type&amp;quot;: &amp;quot;int&amp;quot;,
                &amp;quot;min&amp;quot;: 1,
                &amp;quot;max&amp;quot;: 40},
              {&amp;quot;name&amp;quot;: &amp;quot;lr&amp;quot;,
                &amp;quot;type&amp;quot;: &amp;quot;float&amp;quot;,
                &amp;quot;min&amp;quot;: 0.001,
                &amp;quot;max&amp;quot;: 0.1},
              {&amp;quot;name&amp;quot;: &amp;quot;batch_size&amp;quot;,
               &amp;quot;type&amp;quot;: &amp;quot;discrete_numeric&amp;quot;,
               &amp;quot;items&amp;quot;:&amp;quot;40-61-79-102-120-141-163-183-201-210-225-238&amp;quot;}]

    param_dict = {&amp;quot;name&amp;quot;: &amp;quot;BO_CGCNN&amp;quot;, &amp;quot;domain&amp;quot;: param_list}
    domain_config = load_config(param_dict)
    domain, domain_orderings = domain_config.domain, domain_config.domain_orderings

    # define the hpo search algorithm BO
    func_caller = CPFunctionCaller(None, domain, domain_orderings=domain_orderings)
    optimizer = CPGPBandit(func_caller, ask_tell_mode=True)
    bo_search_alg = DragonflySearch(optimizer, metric=&amp;quot;validation_mae&amp;quot;, mode=&amp;quot;min&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;slurm-job-management&#34;&gt;Slurm — Job Management&lt;/h3&gt;

&lt;p&gt;For those using Slurm, as we do at NERSC, &lt;a href=&#34;https://github.com/NERSC/slurm-ray-cluster&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; are the scripts that enable the use of Ray Tune. The &lt;code&gt;start-head.sh&lt;/code&gt; and &lt;code&gt;start-worker.sh&lt;/code&gt; files can be copied directly; only the submit script requires minor modifications to execute your code on the resource and in the environment of choice. If you run into an issue where worker nodes are not starting and you see an error like this &lt;code&gt;ValueError: The argument None must be a bytes object&lt;/code&gt; extend the sleep time after starting the head node found on this &lt;a href=&#34;https://github.com/NERSC/slurm-ray-cluster/blob/master/submit-ray-cluster.sbatch#L36&#34; target=&#34;_blank&#34;&gt;line&lt;/a&gt;. This is not a bug — the head node needs to set a variable and sometimes it takes a while.&lt;/p&gt;

&lt;h3 id=&#34;tensorboard-logging-visualization&#34;&gt;TensorBoard — Logging/Visualization&lt;/h3&gt;

&lt;p&gt;Ray Tune logs with TensorBoard (TB) by default. A couple thoughts about HPO with TB and Ray Tune:
* TB allows you to easily filter your results, which is important when you run 1000s of trials using ASHA
* Good visualizations with the &lt;a href=&#34;https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams&#34; target=&#34;_blank&#34;&gt;HParams Dashboard&lt;/a&gt;
* TB works great with SHA based strategies in Ray Tune, my only complaint is the integration with PBT is not as good&lt;/p&gt;

&lt;p&gt;For NERSC users &lt;a href=&#34;https://docs.nersc.gov/machinelearning/tensorboard/&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; is how I usually run TB. One downside is that you can only have one TB client open at a time.&lt;/p&gt;

&lt;h3 id=&#34;weights-and-biases-logging-visualization&#34;&gt;Weights and Biases — Logging/Visualization&lt;/h3&gt;

&lt;p&gt;W&amp;amp;B has a &lt;a href=&#34;https://docs.wandb.com/library/integrations/ray-tune&#34; target=&#34;_blank&#34;&gt;logger&lt;/a&gt; that integrates with Ray Tune and I used it with the model I was testing. Clearly a lot of potential exists and in general I like the W&amp;amp;B platform, but at the time (March/April 2020) I had difficulties logging large-scale HPO campaigns with W&amp;amp;B. I believe some updates/upgrades are in progress.&lt;/p&gt;

&lt;h2 id=&#34;key-findings&#34;&gt;Key Findings&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;The ASHA scheduler improved the time-to-solution for my model by at least 10x compared to random search alone&lt;/li&gt;
&lt;li&gt;BO may not always improve average HPO performance, but I was able to find my single best configuration of hyperparameters with ASHA/BO&lt;/li&gt;
&lt;li&gt;Using PBT, I found my optimal learning rate and it can be reasonably modeled with a multistep scheduler&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;key-takeaways&#34;&gt;Key Takeaways&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Ray Tune is a simple and scalable HPO framework&lt;/li&gt;
&lt;li&gt;Using a scheduler to improve HPO efficiency is essential&lt;/li&gt;
&lt;li&gt;More sophisticated search algorithms such as BO likely provide some benefit but are not always worth the investment&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;PBT is great for developing ideal schedulers and for training if the model does not need to be retained frequently&lt;/li&gt;
&lt;li&gt;There is no one-size-fits-all solution to HPO. Start simple and build complexity as needed — ASHA/RS is a reasonable default strategy&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Active Learning Demo</title>
      <link>https://wood-b.github.io/post/active-learning-demo/</link>
      <pubDate>Fri, 10 Apr 2020 12:00:14 -0700</pubDate>
      
      <guid>https://wood-b.github.io/post/active-learning-demo/</guid>
      <description>

&lt;h1 id=&#34;active-learning-on-molecular-systems-with-graphdot-xtb-ase-and-scikit-learn&#34;&gt;Active Learning on Molecular Systems with GraphDot, xTB, ASE, and scikit-learn&lt;/h1&gt;

&lt;p&gt;Original Post: 3/11/2020&lt;/p&gt;

&lt;p&gt;Updated: 4/10/2020&lt;/p&gt;

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Since the end of my PhD (Aug 2019), I have been interested in combining active learning with quantum calculations to explore configuration space in molecular systems. The goal of this post is to explore active learning on a simple system and to put a few ideas out there for people to think about and expand on. The other reason I wanted to make this post is that I think it is really cool how easily GraphDot/xTB/ASE/scikit-learn can be used together, so I thought I would share by example.&lt;/p&gt;

&lt;p&gt;I want to thank &lt;a href=&#34;https://crd.lbl.gov/departments/computational-science/ccmc/staff/alvarez-fellows/yu-hang-tang/&#34; target=&#34;_blank&#34;&gt;Yu-Hang Tang&lt;/a&gt; for all the help with the graph kernel, none of this would have been possible otherwise. If you want to learn more about the graph kernel, check out this &lt;a href=&#34;http://dx.doi.org/10.1063/1.5078640&#34; target=&#34;_blank&#34;&gt;publication&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;If you have any questions or comments shoot me an email bwood@lbl.gov.&lt;/p&gt;

&lt;h2 id=&#34;dependencies&#34;&gt;Dependencies&lt;/h2&gt;

&lt;p&gt;All dependencies can be pip installed with the exception of xTB, which can now be install with &lt;a href=&#34;https://github.com/grimme-lab/xtb&#34; target=&#34;_blank&#34;&gt;conda&lt;/a&gt;, although I used a version I compiled. Additionally, the methods I used from GraphDot require a GPU.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://graphdot.readthedocs.io/en/latest/&#34; target=&#34;_blank&#34;&gt;GraphDot&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://xtb-docs.readthedocs.io/en/latest/contents.html&#34; target=&#34;_blank&#34;&gt;xTB&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://wiki.fysik.dtu.dk/ase/index.html&#34; target=&#34;_blank&#34;&gt;ASE&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;scikit-learn&lt;/li&gt;
&lt;li&gt;Numpy&lt;/li&gt;
&lt;li&gt;Matplotlib&lt;/li&gt;
&lt;li&gt;tqdm&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;conformations-of-polyethylene&#34;&gt;Conformations of Polyethylene&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;./pe_tor_rot.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;description-of-the-system&#34;&gt;Description of the system&lt;/h2&gt;

&lt;p&gt;The toy problem I chose to explore is approximating the energy functional of an ensemble of polyethylene chain conformations. I defined the problem as follows. All chains are made up of 3 monomers — 6 carbon atoms. The rationale for short chains is to keep the degrees of freedom manageable for example purposes. Each chain consists of three C-C-C-C torsion angles ($\phi$$_i$, $\phi$$_j$, $\phi$$_k$) and a conformation is defined as a unique set of the three torsion angles {$\phi$$_i$, $\phi$$_j$, $\phi$$_k$}. I discretized the torsion angle distribution to contain 36 states equally spaced by 10 degrees. The ensemble of conformations is generated by sampling over all of the discrete torsional configurations, so there are ~ $36^3$ conformations — some of these are not unique because of symmetry.&lt;/p&gt;

&lt;h2 id=&#34;description-of-the-active-learning-algorithm&#34;&gt;Description of the active learning algorithm&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;./active_learn_scheme.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The objective is to find a surrogate model for calculating the energy of a chain conformation. Generally speaking, an energy evaluation with density functional theory (DFT) or another level of quantum chemistry is computationally expensive, so if we can generate a reasonable energy prediction (or predict another property of interest) with a machine learning model it saves computational time and expands the systems we can study. In this example, I generate a graph representation of the different conformations using GraphDot and then use a graph kernel with scikit-learn’s Gaussian Process Regression (GPR) to predict energies. I could easily calculate all the conformer energies with xTB; however, if I wanted to use DFT or look at larger systems that would not be possible. As a result, I wanted to implement an active learning strategy. The active learning algorithm I employ is an iterative process where ~1000 conformations are predicted each step, and the 300 conformers with the largest prediction uncertainties are fed back into the training data for the next step. This procedure is intended to ensure that the model sees data that will maximally improve the model each step.&lt;/p&gt;

&lt;h2 id=&#34;imports&#34;&gt;Imports&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numpy as np
import os
import time
from tqdm import tqdm
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import xtb
from xtb import GFN2

import ase
from ase.io import read, write
from ase.units import Hartree
from ase.optimize import BFGSLineSearch
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from graphdot import Graph
from graphdot.graph.adjacency import AtomicAdjacency
from graphdot.kernel.molecular import Tang2019MolecularKernel
from graphdot.kernel.basekernel import KroneckerDelta, SquareExponential, TensorProduct
from graphdot.kernel.marginalized import MarginalizedGraphKernel
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%matplotlib inline
import matplotlib.pyplot as plt
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;generate-dataset-via-torsional-configurations&#34;&gt;Generate dataset via torsional configurations&lt;/h2&gt;

&lt;p&gt;Torsion angles range from 0 to 360 degrees or depending on the convention from -180 to 180 degrees. For the purposes of this demo I am going to use 0 to 360 because it fits naturally with the convention ASE uses.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;torsion_angles = np.linspace(0.0, 350.0, num=36)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;torsion_angles
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;array([  0.,  10.,  20.,  30.,  40.,  50.,  60.,  70.,  80.,  90., 100.,
       110., 120., 130., 140., 150., 160., 170., 180., 190., 200., 210.,
       220., 230., 240., 250., 260., 270., 280., 290., 300., 310., 320.,
       330., 340., 350.])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Generate an array of all combinations for 3 torsion angles ~46,000
this includes all combinations, not all will be unique because of symmetry&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;tor_combinations = np.zeros((46656, 3))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;count = 0
for i in torsion_angles:
    for j in torsion_angles:
        for k in torsion_angles:
            tor_combinations[count] = [i, j, k]
            count += 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Read in the polyethylene molecule&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pe_mol = read(&amp;quot;pe_n6.xyz&amp;quot;, format=&amp;quot;xyz&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Set the energy calculator&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pe_mol.set_calculator(GFN2())
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Check how long it takes to calculate the energy&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%time pe_mol.get_potential_energy()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;CPU times: user 32.6 ms, sys: 8.23 ms, total: 40.9 ms
Wall time: 25 ms

-543.9429310420319
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;relax = BFGSLineSearch(pe_mol)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;relax.run(fmax=0.05)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;                Step[ FC]     Time          Energy          fmax
*Force-consistent energies used in optimization.
BFGSLineSearch:    0[  0] 11:21:41     -543.942931*       0.7441
BFGSLineSearch:    1[  2] 11:21:41     -544.038490*       0.5208
BFGSLineSearch:    2[  4] 11:21:41     -544.057613*       0.1229
BFGSLineSearch:    3[  6] 11:21:41     -544.058974*       0.0662
BFGSLineSearch:    4[  8] 11:21:41     -544.059370*       0.0572
BFGSLineSearch:    5[ 10] 11:21:41     -544.059850*       0.0372

True
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pe_mol.get_potential_energy()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;-544.0598501831128
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;helper-functions-for-generating-data&#34;&gt;Helper functions for generating data&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# this function rotates all the torsion angles of the base molecule to the desired angles
def rotate_all_torsions(base_mol, tor_atoms, tor_angles, rot_indices):
    # copy base mol
    rot_mol = base_mol.copy()
    # loop through all the torsion angles in the conformer
    for i, atom in enumerate(tor_atoms):
        rot_mol.set_dihedral(a1=atom[0], a2=atom[1], a3=atom[2], a4=atom[3], 
                             angle=tor_angles[i], indices=rot_indices[i])
    return rot_mol
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# this function generates all the rotated molecules and calculates their energy
# additionally an energy cutoff of 1 eV is imposed
def generate_data(base_mol, tors_list, tor_atoms, rot_indicies, sample_num):
    mol_list = []
    with tqdm(total=sample_num) as pbar:
        for angles in tors_list:
            rot_mol = rotate_all_torsions(base_mol, tor_atoms, angles, rot_indicies)
            rot_mol.set_calculator(GFN2())
            r_energy = rot_mol.get_potential_energy()
            # energy cutoff of -543.0 eV
            if r_energy &amp;lt; -543.0:
                mol_list.append(rot_mol)
                pbar.update(1)
            else:
                continue
            if len(mol_list) == sample_num:
                break
            else:
                continue
    return mol_list
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;specify-atoms-involved-in-each-torsion-angle&#34;&gt;Specify atoms involved in each torsion angle&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# these are specific for this particular molecule and xyz file ordering
pe_n6_tor_atoms = [[0, 1, 5, 8], [1, 5, 8, 11], [5, 8, 11, 14]]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# these are specific for this particular molecule and xyz file ordering
pe_n6_tor_indices=[[8,9,10,11,12,13,14,15,16,17,18,19], [11,12,13,14,15,16,17,18,19], [14,15,16,17,18,19]]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;generate-and-write-data&#34;&gt;Generate and write data&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# shuffle torsion combinations
random_tors = np.copy(tor_combinations)
np.random.shuffle(random_tors)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# %time mol_list = generate_data(pe_mol, random_tors, pe_n6_tor_atoms, pe_n6_tor_indices, 13000)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# this took 6 mins to run
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# write all 13k ase atom objects into an xyz file
# write(&amp;quot;./data/pe_13k_dataset.xyz&amp;quot;, images=mol_list, format=&amp;quot;xyz&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Comment on calculating all the energies at once&lt;/strong&gt;: Ideally, I would calculate energies on the fly in the active learning loop; however, for simplicity and because of the energy cutoff I am using I did everything at once. If I had done energy calculations in the active learning loop I would have saved myself 7000 energy evaluations — which can save a substantial amount of computational time depending on the method used.&lt;/p&gt;

&lt;h2 id=&#34;read-molecule-data-and-generate-graphs&#34;&gt;Read molecule data and generate graphs&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%time mol_list = read(&amp;quot;./data/pe_13k_dataset.xyz&amp;quot;, index=&amp;quot;:&amp;quot;, format=&amp;quot;xyz&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;CPU times: user 5.53 s, sys: 259 ms, total: 5.78 s
Wall time: 5.77 s
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# parameter for generating graphs
adj = AtomicAdjacency(shape=&#39;tent2&#39;, zoom=2.0)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# this function gets the input graphs and target energies
def get_xy_data(mols, adj):
    # shuffle the mols again
    random_mols = np.copy(mols)
    np.random.shuffle(random_mols)
    energy_array = np.array([mol.get_potential_energy() for mol in mols])
    graph_array = np.array([Graph.from_ase(mol, adjacency=adj) for mol in mols])
    return graph_array, energy_array
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%time graphs, energies = get_xy_data(mol_list, adj)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;CPU times: user 47.3 s, sys: 367 ms, total: 47.6 s
Wall time: 47.6 s
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;define-the-graph-kernel&#34;&gt;Define the graph kernel&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;mol_kernel = Tang2019MolecularKernel(edge_length_scale=0.02, stopping_probability=0.01)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In order to use scikit-learn&amp;rsquo;s GPR we need to define a MarginalizedGraphKernel object. The kernel defined below is essentially the same as the Tang2019MolecularKernel. I double check that assumption below.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;kernel = MarginalizedGraphKernel(node_kernel=TensorProduct(element=KroneckerDelta(0.2)), 
                                 edge_kernel=TensorProduct(length=SquareExponential(0.02)), 
                                 q=0.01)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;check-graphs-and-visualize-similarity-matrix&#34;&gt;Check graphs and visualize similarity matrix&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;try_graphs = graphs[:500]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;try_energies = energies[:500]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;R_mol = mol_kernel(try_graphs, lmin=1).astype(np.float)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;D_mol = R_mol.diagonal()**-0.5
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;K_mol = D_mol[:, None] * R_mol * D_mol[None, :]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# visualize the similarity matrix
plt.imshow(K_mol)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;matplotlib.image.AxesImage at 0x2aab24d429d0&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./active_learning_demo_7_write_files_60_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;K_mol.max()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;1.000000173664869
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;K_mol.min()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0.8706799071173481
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;R = kernel(try_graphs, lmin=1).astype(np.float)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;D = R.diagonal()**-0.5
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;K = D[:, None] * R * D[None, :]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# visualize the similarity matrix
plt.imshow(K)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;matplotlib.image.AxesImage at 0x2aab24de3d10&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./active_learning_demo_7_write_files_66_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The yellow diagonal represents when conformers are compared to themselves&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;K.max()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;1.000000249324106
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;K.min()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0.8706799071173481
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The minimum similarity is fairly high, which isn&amp;rsquo;t that surprising considering I am comparing the same molecule just with different torsional rotations.&lt;/p&gt;

&lt;h2 id=&#34;calculate-a-specific-torsion-potential-for-benchmarking&#34;&gt;Calculate a specific torsion potential for benchmarking&lt;/h2&gt;

&lt;p&gt;To track how the model improves at each step, I generate the inputs and targets for a specific torsion potential to benchmark against. Arbitrarily, I chose the central torsion angle $\phi$$_j$, leaving $\phi$$_i$ and $\phi$$_k$ fixed. In the future, it would be nice to guarantee these benchmarking data points were held out of the training set, right now, they may or may not be included.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def get_torsion_pot(base_mol, tor_atoms, tor_angles, rot_indices, adj):
    tor_graphs = []
    tor_energies = []
    for angle in tor_angles:
        rot_mol = rotate_all_torsions(base_mol, tor_atoms, [angle], rot_indices)
        rot_mol.set_calculator(GFN2())
        tor_energies.append(rot_mol.get_potential_energy())
        tor_graphs.append(Graph.from_ase(rot_mol, adjacency=adj))
    return tor_energies, tor_graphs
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# these are specific for this particular molecule and xyz file ordering
pe_t2_tor_atoms = [[1, 5, 8, 11]]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# these are specific for this particular molecule and xyz file ordering
pe_t2_tor_indices=[[11,12,13,14,15,16,17,18,19]]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;tor_pot_angles = np.linspace(0.0, 360.0, num=37)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;tor_pot_sp_energies, tor_pot_graphs = get_torsion_pot(pe_mol, pe_t2_tor_atoms, tor_pot_angles, pe_t2_tor_indices, adj)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;active-learning-object&#34;&gt;Active learning object&lt;/h2&gt;

&lt;p&gt;This is a simple class to help organize the active learning loop. ActiveGPR initializes a scikit-learn GPR model and has train, explore, updata_data, and calc_metrics methods.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class ActiveGPR():
    def __init__(self, kernel, X_train, y_train, X_val, y_val, X_tor_pot):
        self.X_train = X_train
        self.y_train = y_train
        self.X_val = X_val
        self.y_val = y_val
        self.X_tor_pot = X_tor_pot
        self.uncertain = None
        # the default alpha value needs to be adjusted and 
        # normalize y is turned on because our energies do not have a mean of zero
        self.gpr = GaussianProcessRegressor(kernel=kernel, optimizer=None, alpha=0.02, normalize_y=True)
        self.metrics = {&amp;quot;step&amp;quot;: [], &amp;quot;rmse&amp;quot;: [], &amp;quot;mae&amp;quot;: [], &amp;quot;r2&amp;quot;: []}
        self.pred_pot = []
        self.step = 0
        
    def train(self):
        self.gpr.fit(self.X_train, self.y_train);
        self.calc_metrics(self.X_val, self.y_val)
        self.pred_pot.append(self.gpr.predict(self.X_tor_pot, return_std=True))
        self.step += 1
    
    def explore(self, X_new, sample_num=300):
        y_pred, y_std = self.gpr.predict(X_new, return_std=True)
        # np.argsort sorts from min to max so selecting from the end of array gives
        # the max uncertainty
        uncertain_indexes = np.argsort(y_std)
        self.uncertain = uncertain_indexes[(len(uncertain_indexes) - sample_num):]

    def update_data(self, X, y):
        X_new = np.array(X)[self.uncertain]
        y_new = np.array(y)[self.uncertain]
        X_train = np.concatenate((self.X_train, X_new), axis=0)
        y_train = np.concatenate((self.y_train, y_new), axis=0)
        # shuffle data
        shuffle_ind = np.arange(len(X_train))
        np.random.shuffle(shuffle_ind)
        self.X_train = X_train[shuffle_ind]
        self.y_train = y_train[shuffle_ind]
        
    def calc_metrics(self, X, y):
        y_pred = self.gpr.predict(X)
        r2 = r2_score(y, y_pred)
        rmse = mean_squared_error(y, y_pred, squared=False) 
        mae = mean_absolute_error(y, y_pred)
        self.metrics[&amp;quot;rmse&amp;quot;].append(rmse)
        self.metrics[&amp;quot;mae&amp;quot;].append(mae)
        self.metrics[&amp;quot;r2&amp;quot;].append(r2)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;active-learning-loop&#34;&gt;Active learning loop&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# define train, val, and test sets
def train_val_test_split(energies, graphs, val_size, test_size, initial_size, active_size):
    X_test = graphs[:test_size]
    y_test = energies[:test_size]
    X_val = graphs[test_size:(test_size + val_size)]
    y_val = energies[test_size:(test_size + val_size)]
    # returns the train set
    train_size = int(len(energies) - (test_size + val_size))
    splits = np.arange(initial_size, train_size, active_size)
    X_train_set = np.split(graphs[(test_size + val_size):], splits, axis=0)
    y_train_set = np.split(energies[(test_size + val_size):], splits, axis=0)
    return X_train_set, y_train_set, X_val, y_val, X_test, y_test
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;X_train, y_train, X_val, y_val, X_test, y_test = train_val_test_split(energies, graphs, 1000, 1000, 1000, 1000)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pe_gpr = ActiveGPR(kernel, X_train[0], y_train[0], X_val, y_val, tor_pot_graphs)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# active learning loop
active_steps = range(0, 11)
for step in active_steps:
    s_time = time.perf_counter()
    print(&amp;quot;Learning Step: {s}&amp;quot;.format(s=pe_gpr.step))
    print(&amp;quot;Training Data Size: {d}&amp;quot;.format(d=len(pe_gpr.X_train)))
    
    pe_gpr.train()
    #X_new, y_new = generate_data(pe_mol, train_tor_list[step + 1], pe_n6_tor_atoms, pe_n6_tor_indices, adj, 1000)
    if step != len(active_steps) - 1:
        X_new = X_train[step + 1]
        y_new = y_train[step + 1]
        pe_gpr.explore(X_new)
        pe_gpr.update_data(X_new, y_new)
    
    e_time = time.perf_counter()
    
    print(&amp;quot;MAE: {mae:0.3f}&amp;quot;.format(mae=pe_gpr.metrics[&amp;quot;mae&amp;quot;][step]))
    print(&amp;quot;RMSE: {rmse:0.3f}&amp;quot;.format(rmse=pe_gpr.metrics[&amp;quot;rmse&amp;quot;][step]))
    print(&amp;quot;R-squared: {r2:0.5f}&amp;quot;.format(r2=pe_gpr.metrics[&amp;quot;r2&amp;quot;][step]))
    print(&amp;quot;Step Time(s): {t:0.2f}&amp;quot;.format(t=(e_time - s_time)))
    print(&amp;quot;---------- End of Step ----------&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Learning Step: 0
Training Data Size: 1000
      0.5 ms on generating jobs
      0.2 ms on creating output buffer
      0.7 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
      8.9 ms on code generation
    190.7 ms on JIT
      1.1 ms on calculating launch configuration
      3.8 ms on GPU kernel execution
    205.7 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
      0.8 ms on generating jobs
      0.3 ms on creating output buffer
      7.5 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
     15.8 ms on code generation
    179.1 ms on JIT
      2.3 ms on calculating launch configuration
      5.1 ms on GPU kernel execution
    210.3 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
MAE: 0.018
RMSE: 0.029
R-squared: 0.98452
Step Time(s): 13.47
---------- End of Step ----------
Learning Step: 1
Training Data Size: 1300
      0.5 ms on generating jobs
      0.3 ms on creating output buffer
      0.7 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
      8.9 ms on code generation
    192.6 ms on JIT
      0.5 ms on calculating launch configuration
      2.1 ms on GPU kernel execution
    205.1 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
      0.5 ms on generating jobs
      0.3 ms on creating output buffer
     13.5 ms on transferring graphs to GPU
      0.2 ms on allocate global job counter
     12.2 ms on code generation
    189.0 ms on JIT
      2.6 ms on calculating launch configuration
      5.0 ms on GPU kernel execution
    222.8 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
MAE: 0.014
RMSE: 0.022
R-squared: 0.99173
Step Time(s): 16.96
---------- End of Step ----------
Learning Step: 2
Training Data Size: 1600
      0.5 ms on generating jobs
      0.3 ms on creating output buffer
      0.7 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
      8.7 ms on code generation
    188.6 ms on JIT
      0.5 ms on calculating launch configuration
      1.7 ms on GPU kernel execution
    200.6 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
      0.6 ms on generating jobs
      0.3 ms on creating output buffer
     12.7 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
     12.5 ms on code generation
    186.0 ms on JIT
      2.1 ms on calculating launch configuration
      5.2 ms on GPU kernel execution
    219.0 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
MAE: 0.011
RMSE: 0.017
R-squared: 0.99502
Step Time(s): 22.28
---------- End of Step ----------
Learning Step: 3
Training Data Size: 1900
      0.5 ms on generating jobs
      0.3 ms on creating output buffer
      0.7 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
      8.8 ms on code generation
    191.2 ms on JIT
      0.5 ms on calculating launch configuration
      1.9 ms on GPU kernel execution
    203.3 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
      0.6 ms on generating jobs
      0.3 ms on creating output buffer
     15.4 ms on transferring graphs to GPU
      0.3 ms on allocate global job counter
     13.5 ms on code generation
    186.4 ms on JIT
      3.1 ms on calculating launch configuration
      5.6 ms on GPU kernel execution
    224.6 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
MAE: 0.010
RMSE: 0.015
R-squared: 0.99611
Step Time(s): 28.16
---------- End of Step ----------
Learning Step: 4
Training Data Size: 2200
      0.5 ms on generating jobs
      0.3 ms on creating output buffer
      0.8 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
      9.0 ms on code generation
    187.0 ms on JIT
      0.5 ms on calculating launch configuration
      1.8 ms on GPU kernel execution
    199.5 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
      0.5 ms on generating jobs
      0.2 ms on creating output buffer
     12.6 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
     12.4 ms on code generation
    188.6 ms on JIT
      2.3 ms on calculating launch configuration
      5.3 ms on GPU kernel execution
    221.6 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
MAE: 0.009
RMSE: 0.013
R-squared: 0.99690
Step Time(s): 34.71
---------- End of Step ----------
Learning Step: 5
Training Data Size: 2500
      0.5 ms on generating jobs
      0.4 ms on creating output buffer
      0.7 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
      8.7 ms on code generation
    183.8 ms on JIT
      0.5 ms on calculating launch configuration
      1.8 ms on GPU kernel execution
    195.8 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
      0.6 ms on generating jobs
      0.2 ms on creating output buffer
     13.4 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
     12.2 ms on code generation
    155.7 ms on JIT
      2.3 ms on calculating launch configuration
      5.2 ms on GPU kernel execution
    189.2 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
MAE: 0.008
RMSE: 0.012
R-squared: 0.99732
Step Time(s): 42.01
---------- End of Step ----------
Learning Step: 6
Training Data Size: 2800
      0.5 ms on generating jobs
      0.3 ms on creating output buffer
      0.7 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
      8.6 ms on code generation
    182.4 ms on JIT
      0.5 ms on calculating launch configuration
      1.7 ms on GPU kernel execution
    194.2 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
      0.5 ms on generating jobs
      0.3 ms on creating output buffer
     13.1 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
     12.3 ms on code generation
    186.8 ms on JIT
      2.3 ms on calculating launch configuration
      5.4 ms on GPU kernel execution
    220.4 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
MAE: 0.007
RMSE: 0.011
R-squared: 0.99783
Step Time(s): 50.00
---------- End of Step ----------
Learning Step: 7
Training Data Size: 3100
      0.6 ms on generating jobs
      0.4 ms on creating output buffer
      0.8 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
      9.0 ms on code generation
    172.8 ms on JIT
      0.5 ms on calculating launch configuration
      1.7 ms on GPU kernel execution
    185.2 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
      0.6 ms on generating jobs
      0.3 ms on creating output buffer
     13.9 ms on transferring graphs to GPU
      0.2 ms on allocate global job counter
     13.2 ms on code generation
    190.5 ms on JIT
      2.2 ms on calculating launch configuration
      5.0 ms on GPU kernel execution
    225.4 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
MAE: 0.007
RMSE: 0.010
R-squared: 0.99812
Step Time(s): 58.98
---------- End of Step ----------
Learning Step: 8
Training Data Size: 3400
      0.6 ms on generating jobs
      0.3 ms on creating output buffer
      0.8 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
      8.7 ms on code generation
    173.3 ms on JIT
      0.5 ms on calculating launch configuration
      1.8 ms on GPU kernel execution
    185.4 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
      0.5 ms on generating jobs
      0.3 ms on creating output buffer
     14.1 ms on transferring graphs to GPU
      0.2 ms on allocate global job counter
     12.6 ms on code generation
    188.5 ms on JIT
      2.3 ms on calculating launch configuration
      5.2 ms on GPU kernel execution
    223.3 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
MAE: 0.007
RMSE: 0.009
R-squared: 0.99849
Step Time(s): 68.16
---------- End of Step ----------
Learning Step: 9
Training Data Size: 3700
      0.5 ms on generating jobs
      0.4 ms on creating output buffer
      0.7 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
      8.8 ms on code generation
    166.4 ms on JIT
      0.5 ms on calculating launch configuration
      1.8 ms on GPU kernel execution
    178.5 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
      0.8 ms on generating jobs
      0.3 ms on creating output buffer
     13.6 ms on transferring graphs to GPU
      0.2 ms on allocate global job counter
     17.0 ms on code generation
    190.8 ms on JIT
      2.4 ms on calculating launch configuration
      5.0 ms on GPU kernel execution
    229.4 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
MAE: 0.006
RMSE: 0.009
R-squared: 0.99859
Step Time(s): 77.91
---------- End of Step ----------
Learning Step: 10
Training Data Size: 4000
      0.5 ms on generating jobs
      0.5 ms on creating output buffer
      0.8 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
      8.9 ms on code generation
    163.4 ms on JIT
      0.5 ms on calculating launch configuration
      1.7 ms on GPU kernel execution
    175.7 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
MAE: 0.006
RMSE: 0.008
R-squared: 0.99879
Step Time(s): 73.67
---------- End of Step ----------
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;plot-validation-mae-and-rmse&#34;&gt;Plot Validation MAE and RMSE&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;fig = plt.figure()
ax = plt.subplot(111)
ax.plot(range(0,11), pe_gpr.metrics[&amp;quot;mae&amp;quot;])
ax.set_xlabel(&amp;quot;Active Learning Step&amp;quot;, fontsize=15)
ax.set_ylabel(&amp;quot;MAE\n(eV)&amp;quot;, rotation=0, labelpad=30, fontsize=15)
#ax.set_ylim(0.00, 0.14)
ax.spines[&amp;quot;right&amp;quot;].set_visible(False)
ax.spines[&amp;quot;top&amp;quot;].set_visible(False)
#plt.title(&amp;quot;&amp;quot;, fontsize=15)
#ax.legend([], frameon=False)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./active_learning_demo_7_write_files_87_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;fig = plt.figure()
ax = plt.subplot(111)
ax.plot(range(0,11), pe_gpr.metrics[&amp;quot;rmse&amp;quot;], c=&amp;quot;C1&amp;quot;)
ax.set_xlabel(&amp;quot;Active Learning Step&amp;quot;, fontsize=15)
ax.set_ylabel(&amp;quot;RMSE\n(eV)&amp;quot;, rotation=0, labelpad=30, fontsize=15)
#ax.set_ylim(0.00, 0.14)
ax.spines[&amp;quot;right&amp;quot;].set_visible(False)
ax.spines[&amp;quot;top&amp;quot;].set_visible(False)
#plt.title(&amp;quot;&amp;quot;, fontsize=15)
#ax.legend([], frameon=False)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./active_learning_demo_7_write_files_88_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;test-mae-and-rmse&#34;&gt;Test MAE and RMSE&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pe_gpr.calc_metrics(X_test, y_test)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(&amp;quot;MAE: {mae:0.3f}&amp;quot;.format(mae=pe_gpr.metrics[&amp;quot;mae&amp;quot;][-1]))
print(&amp;quot;RMSE: {rmse:0.3f}&amp;quot;.format(rmse=pe_gpr.metrics[&amp;quot;rmse&amp;quot;][-1]))
print(&amp;quot;R-squared: {r2:0.5f}&amp;quot;.format(r2=pe_gpr.metrics[&amp;quot;r2&amp;quot;][-1]))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;MAE: 0.006
RMSE: 0.008
R-squared: 0.99888
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The final MAE and RMSE values are encouraging. For reference, chemical accuracy — the requirement to make useful chemical predictions — is generally considered to be 1 kcal/mol or ~ 0.04 eV. The final MAE value of 0.006 eV is well within that range, which is great, but there are a few caveats. For one, I used an energy cutoff of 1 eV so that limited the overall energy distribution. It would be interesting to compare my results to randomly guessing energy values within the 1 eV window. Additionally, torsional energy barriers can be low (&amp;lt; 0.025 eV), as a result we would hope that we could resolve those features in the potential energy surface.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Comment on the coefficient of determination ($R^2$):&lt;/strong&gt; The interpretation of $R^2$ in this context is not entirely clear to me, but it says something about the amount of variance accounted for by the GPR model. It also tells us that our model is better than a model that always predicts the mean value of y regardless of the input features ($R^2$ = 0). &lt;strong&gt;TL;DR&lt;/strong&gt; $R^2$ values increase with each active learning step indicating the model is improving.&lt;/p&gt;

&lt;h2 id=&#34;predicting-torsion-potentials&#34;&gt;Predicting torsion potentials&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# torsion potentials are displayed using relative energies
rel_sp_energies = np.array(tor_pot_sp_energies) - min(tor_pot_sp_energies)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;rel_tor_predict = [array[0] - min(array[0]) for array in pe_gpr.pred_pot]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# propagate the error (energy – min(energy)) 
tor_std_prop = []
for array in pe_gpr.pred_pot:
    min_index = np.argmin(array[0])
    err_prop = np.sqrt(np.power(array[1], 2) + np.power(array[1][min_index], 2))
    tor_std_prop.append(err_prop)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def tor_pot_plot(rel_energy, rel_predict, std, color, ylim=(-0.2, 0.45)):
    fig = plt.figure()
    ax = plt.subplot(111)
    ax.plot(tor_pot_angles, rel_energy)
    ax.plot(tor_pot_angles, rel_predict, &amp;quot;o&amp;quot;, c=color)
    #ax.errorbar(tor_pot_angles, rel_predict, yerr=std, fmt=&amp;quot;o&amp;quot;, c=color)
    ax.fill_between(tor_pot_angles, rel_predict - std, rel_predict + std, alpha=0.125)
    ax.set_xlabel(r&amp;quot;Torsion Angle ($\degree$)&amp;quot;, fontsize=15)
    ax.set_ylabel(&amp;quot;Relative\nEnergy (eV)&amp;quot;, rotation=0, labelpad=50, fontsize=15)
    ax.set_ylim(ylim)
    ax.set_yticks([0.00, 0.15, 0.35])
    ax.set_xticks([0, 180, 360])
    ax.spines[&amp;quot;right&amp;quot;].set_visible(False)
    ax.spines[&amp;quot;top&amp;quot;].set_visible(False)
    ax.legend([&amp;quot;True&amp;quot;, &amp;quot;Predict&amp;quot;, &amp;quot;Predict Uncertainty&amp;quot;], loc=&amp;quot;upper right&amp;quot;, bbox_to_anchor=(1.4 ,1), frameon=False)
    return fig.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;torsion-potential-after-initial-training&#34;&gt;Torsion potential after initial training&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;tor_pot_plot(rel_sp_energies, rel_tor_predict[0], tor_std_prop[0], &amp;quot;C6&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./active_learning_demo_7_write_files_100_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;torsion-potential-after-step-5&#34;&gt;Torsion potential after step 5&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;tor_pot_plot(rel_sp_energies, rel_tor_predict[5], tor_std_prop[5], &amp;quot;C4&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./active_learning_demo_7_write_files_102_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;torsion-potential-after-step-10&#34;&gt;Torsion potential after step 10&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;tor_pot_plot(rel_sp_energies, rel_tor_predict[10], tor_std_prop[10], &amp;quot;C1&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./active_learning_demo_7_write_files_104_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Comment on the torsion potential data&lt;/strong&gt;: It is possible that the model saw some of these points during training.&lt;/p&gt;

&lt;h2 id=&#34;predicting-relaxed-torsion-potentials&#34;&gt;Predicting relaxed torsion potentials&lt;/h2&gt;

&lt;p&gt;All the previous data points are single point energies, meaning that I took the initial relaxed structured, rotated the torsion angles, and calculated the energies without doing another relaxation step. Generally, when calculating a torsion potential, I would constrain the torsion angle of interest and do another relaxation. It turns out this is currently not possible with the xTB/ASE combination, but it is very simple to in xTB without the ASE interface. As a result, I read in the files from xTB. The relaxed molecules are guaranteed&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# read in the relaxed molecules
relax_tor_mols = read(&amp;quot;./xtbscan.log&amp;quot;, index=&amp;quot;:&amp;quot;, format=&amp;quot;xyz&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;relax_tor_graphs = [Graph.from_ase(mol, adjacency=adj) for mol in relax_tor_mols]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# read in the energies
relax_tor_ev_energies = []
with open(&amp;quot;./xtbscan.log&amp;quot;) as file:
    for i, line in enumerate(file):
        if &amp;quot;SCF done&amp;quot; in line:
            # energies are in Hatrees
            tor_ha_energy = float(line.split()[2])
            relax_tor_ev_energies.append(tor_ha_energy * 27.211386245988)  
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# relative energies
rel_relax_tor_energies = np.array(relax_tor_ev_energies) - min(relax_tor_ev_energies)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;relax_tor_predict, relax_tor_std = pe_gpr.gpr.predict(relax_tor_graphs, return_std=True)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;      0.5 ms on generating jobs
      0.4 ms on creating output buffer
      0.8 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
      8.9 ms on code generation
    193.2 ms on JIT
      0.4 ms on calculating launch configuration
      2.0 ms on GPU kernel execution
    205.6 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# relative predicted energies
rel_relax_tor_predict = np.array(relax_tor_predict) - min(relax_tor_predict)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# propagate the error (energy – min(energy))
min_i = np.argmin(rel_relax_tor_energies)
relax_tor_std_prop = np.sqrt(np.power(relax_tor_std, 2) + np.power(relax_tor_std[min_i], 2))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;tor_pot_plot(rel_relax_tor_energies, rel_relax_tor_predict, relax_tor_std_prop, &amp;quot;C2&amp;quot;, ylim=(-0.1, 0.35))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./active_learning_demo_7_write_files_115_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Predicting the energy of relaxed structures is not fantastic but the shape of the potential is roughly correct, and the good news is that the model knows what it doesn’t know. The prediction uncertainty for these is high compared to the previous torsion potential predictions. Relaxations cause fluctuations in other degrees of freedom such as bond lengths and bond angles, which the model was not trained on. So, if predicting the energy of relaxed structures is the goal some examples should be included in the training set.&lt;/p&gt;

&lt;h1 id=&#34;conclusions&#34;&gt;Conclusions&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;The graphs and molecular graph kernel from GraphDot have enough resolution to tell the difference between torsional conformers of the same molecule&lt;/li&gt;
&lt;li&gt;Good energy predictions ($&amp;lt;k_BT$) can be achieved on small datasets with the implemented graph kernel and GPR model&lt;/li&gt;
&lt;li&gt;Prediction uncertainties are very useful and a huge advantage of a GPR model. Chemistry or materials science problems where generating semi-realistic structures is easy but energy evaluations are expensive are most likely to fully leverage the advantages of GPR.&lt;/li&gt;
&lt;li&gt;If predicting the energy of relaxed structures is the objective, at least some relaxed structures should be included in the training dataset&lt;/li&gt;
&lt;li&gt;The algorithm presented here will not work for all molecular systems but I think everyone can appreciate the software integration :)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;future-extensions&#34;&gt;Future Extensions&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Predicting structures — It would be nice to be able to predict low energy conformations. One way to do this is write an optimizer in ASE and use the GPR model as a surrogate for the energy calculation.&lt;/li&gt;
&lt;li&gt;Extrapolation to larger polymers — One potential way to extend the toy example I presented here is to predict the energy of a chain that is roughly the same size as the torsional correlation length. Beyond that length segments are uncorrelated and one might be able to extrapolate energy predictions to much larger polymers.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;known-issues&#34;&gt;Known Issues&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;The validation and test sets are potentially contaminated, because I did not account for the symmetry present in the example system.&lt;/li&gt;
&lt;li&gt;Energies were not calculated on-the-fly in the active learning loop. I did this to keep things simple, but there is no reason it couldn’t be done in the future.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Aromaticity as a Guide to Planarity in Conjugated Molecules and Polymers</title>
      <link>https://wood-b.github.io/publication/aromaticity_as_a_guide_to_planarity_in_conjugated_molecules_and_polymers/</link>
      <pubDate>Wed, 12 Feb 2020 00:00:00 -0600</pubDate>
      
      <guid>https://wood-b.github.io/publication/aromaticity_as_a_guide_to_planarity_in_conjugated_molecules_and_polymers/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Conformational Entropy as a Means to Control the Behavior of Poly (diketoenamine) Vitrimers In and Out of Equilibrium</title>
      <link>https://wood-b.github.io/publication/conformational-entropy-vitrimers/</link>
      <pubDate>Tue, 15 Oct 2019 00:00:00 -0500</pubDate>
      
      <guid>https://wood-b.github.io/publication/conformational-entropy-vitrimers/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Ion Transport and the True Transference Number in Nonaqueous Polyelectrolyte Solutions for Lithium-Ion Batteries</title>
      <link>https://wood-b.github.io/publication/ion-transport-polyelectrolyte-solutions/</link>
      <pubDate>Fri, 14 Jun 2019 00:00:00 -0500</pubDate>
      
      <guid>https://wood-b.github.io/publication/ion-transport-polyelectrolyte-solutions/</guid>
      <description></description>
    </item>
    
    <item>
      <title>High-throughput Chemistry</title>
      <link>https://wood-b.github.io/project/high-throughput-chemistry/</link>
      <pubDate>Wed, 19 Dec 2018 14:15:49 -0800</pubDate>
      
      <guid>https://wood-b.github.io/project/high-throughput-chemistry/</guid>
      <description>&lt;p&gt;With the rise of modern high performance computers, it is possible to run quantum and classical simulations in automated high-throughput fashion. I have contributed to a number of open source repositories that enable high-throughput chemistry and materials science. The software stack includes: &lt;a href=&#34;https://github.com/materialsproject/pymatgen&#34; target=&#34;_blank&#34;&gt;pymatgen&lt;/a&gt;, &lt;a href=&#34;https://github.com/materialsproject/custodian&#34; target=&#34;_blank&#34;&gt;custodian&lt;/a&gt;, and &lt;a href=&#34;https://github.com/hackingmaterials/atomate&#34; target=&#34;_blank&#34;&gt;atomate&lt;/a&gt;. Check out our &lt;a href=&#34;https://doi.org/10.1016/j.commatsci.2017.07.030&#34; target=&#34;_blank&#34;&gt;atomate&lt;/a&gt; publication.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Conjugated Polymers</title>
      <link>https://wood-b.github.io/project/conjugated-polymers/</link>
      <pubDate>Wed, 19 Dec 2018 11:28:58 -0800</pubDate>
      
      <guid>https://wood-b.github.io/project/conjugated-polymers/</guid>
      <description>&lt;p&gt;In macromolecules, there are numerous examples where structure dictates function including electronic conductivity of conjugated polymer materials. To elucidate the structure of doped and excited conjugated polymers we developed a multiscale model that captures electronic structure rearrangement and stochastically generates polymer chain conformations.&lt;/p&gt;

&lt;p&gt;Two forthcoming publications will expand upon the impact of doping and excitation on conjugated polymer structure and the model/code (see above) used to generate chain conformations. Please check back early in the new year for updates.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Elastic Tensor ML</title>
      <link>https://wood-b.github.io/project/elastic-tensor-ml/</link>
      <pubDate>Wed, 19 Dec 2018 11:28:58 -0800</pubDate>
      
      <guid>https://wood-b.github.io/project/elastic-tensor-ml/</guid>
      <description>&lt;p&gt;The Materials Project contains ~87,000 total materials with ~13,500 elastic tensors, which are computationally intensive to calculate from first principles. Although the total number computed will continue to grow, it would be nice to use the data we already have to predict elastic properties such as bulk and shear modulus for materials where the elastic tensor is yet to be calculated. As a result, the goals of this project are to compare machine learning (ML) models for predicting the bulk modulus, and to update the previous model that was trained on a smaller data set. For example Jupyter Notebooks follow the code link above.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Elucidating Solvation Structures for Rational Design of Multivalent Electrolytes — A Review</title>
      <link>https://wood-b.github.io/publication/elucidating-solvation-structures-for-rational-design-of-multivalent-electrolytes-a-review/</link>
      <pubDate>Thu, 26 Apr 2018 00:00:00 -0500</pubDate>
      
      <guid>https://wood-b.github.io/publication/elucidating-solvation-structures-for-rational-design-of-multivalent-electrolytes-a-review/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The Interplay between Salt Association and the Dielectric Properties of Low Permittivity Electrolytes: The Case of LiPF6 and LiAsF6 in Dimethyl Carbonate</title>
      <link>https://wood-b.github.io/publication/the-interplay-between-salt-association-and-the-dielectric-properties-of-low-permittivity-electrolytes-the-case-of-lipf6-and-liasf6-in-dimethyl-carbonate/</link>
      <pubDate>Wed, 20 Dec 2017 00:00:00 -0600</pubDate>
      
      <guid>https://wood-b.github.io/publication/the-interplay-between-salt-association-and-the-dielectric-properties-of-low-permittivity-electrolytes-the-case-of-lipf6-and-liasf6-in-dimethyl-carbonate/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Atomate: A High Level Interface to Generate, Execute, and Analyze Computational Materials Science Workflows</title>
      <link>https://wood-b.github.io/publication/atomate-a-high-level-interface-to-generate-execute-and-analyze-computational-materials-science-workflows/</link>
      <pubDate>Fri, 04 Aug 2017 00:00:00 -0500</pubDate>
      
      <guid>https://wood-b.github.io/publication/atomate-a-high-level-interface-to-generate-execute-and-analyze-computational-materials-science-workflows/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
