<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 3.2.0">
  <meta name="generator" content="Hugo 0.68.3" />
  <meta name="author" content="Brandon Wood">

  
  
  
  
    
  
  <meta name="description" content="Active Learning on Molecular Systems with GraphDot, xTB, ASE, and scikit-learn Original Post: 3/11/2020
Updated: 4/10/2020
Introduction Since the end of my PhD (Aug 2019), I have been interested in combining active learning with quantum calculations to explore configuration space in molecular systems. The goal of this post is to explore active learning on a simple system and to put a few ideas out there for people to think about and expand on.">

  
  <link rel="alternate" hreflang="en-us" href="https://wood-b.github.io/post/active-learning-demo/">

  


  

  

  

  

  

  

  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha256-eSi1q2PG6J7g7ib17yAaWMcrr5GrtohYChqibrV7PBE=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css" integrity="sha384-5sAR7xN1Nv6T6+dT2mhtzEpVJvfS3NScPQTrOxhwjIuvcA67KV2R5Jz6kr4abQsz" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" crossorigin="anonymous">
        
      
    

    

    

  

  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700|Roboto:400,400italic,700|Roboto+Mono">
  

  <link rel="stylesheet" href="/styles.css">
  

  
  
  

  
  <link rel="alternate" href="https://wood-b.github.io/index.xml" type="application/rss+xml" title="">
  <link rel="feed" href="https://wood-b.github.io/index.xml" type="application/rss+xml" title="">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://wood-b.github.io/post/active-learning-demo/">

  
  
  
  
    
  
  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="">
  <meta property="og:url" content="https://wood-b.github.io/post/active-learning-demo/">
  <meta property="og:title" content="Active Learning Demo | ">
  <meta property="og:description" content="Active Learning on Molecular Systems with GraphDot, xTB, ASE, and scikit-learn Original Post: 3/11/2020
Updated: 4/10/2020
Introduction Since the end of my PhD (Aug 2019), I have been interested in combining active learning with quantum calculations to explore configuration space in molecular systems. The goal of this post is to explore active learning on a simple system and to put a few ideas out there for people to think about and expand on."><meta property="og:image" content="https://wood-b.github.io/post/active-learning-demo/featured.png">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2020-04-10T12:00:14-07:00">
  
  <meta property="article:modified_time" content="2020-04-10T12:00:14-07:00">
  

  

  

  <title>Active Learning Demo | </title>

</head>
<body id="top" data-spy="scroll" data-target="#TableOfContents" data-offset="71" >
  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" role="textbox" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/"></a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav ml-auto">
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#projects">
            
            <span>Projects</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#publications">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#posts">
            
            <span>Posts</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/files/cv_website_feb2020.pdf">
            
            <span>CV</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#contact">
            
            <span>Contact</span>
            
          </a>
        </li>

        
        

      

        

        
        <li class="nav-item">
          <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        

        
        <li class="nav-item">
          <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
        </li>
        

      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  













<div class="article-header d-xl-none">
  <div class="featured-image" style="background-image: url('/post/active-learning-demo/featured_hu8f0b9e05b19aec9f0cc40148fcb05085_95323_800x0_resize_box_2.png');"></div>
  
</div>


<div class="container-fluid split-header d-none d-xl-block">
  <div class="row">
    <div class="col-6">
      <div class="split-header-content">
        <h1 itemprop="name">Active Learning Demo</h1>

        

        

<div class="article-metadata">

  
  
  
  <div>
    <span itemscope itemprop="author" itemtype="http://schema.org/Person">
      <span itemprop="name">Brandon M. Wood</span>
    </span>
    
  </div>
  

  <span class="article-date">
    
    <meta content="2020-04-10 12:00:14 -0700 -0700" itemprop="datePublished">
    <time datetime="2020-04-10 12:00:14 -0700 -0700" itemprop="dateModified">
      Apr 10, 2020
    </time>
  </span>
  <span itemscope itemprop="publisher" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Brandon Wood">
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    21 min read
  </span>
  

  
  

  

  

</div>


        







  










        
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=Active%20Learning%20Demo&amp;url=https%3a%2f%2fwood-b.github.io%2fpost%2factive-learning-demo%2f"
         target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fwood-b.github.io%2fpost%2factive-learning-demo%2f"
         target="_blank" rel="noopener">
        <i class="fab fa-facebook-f"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fwood-b.github.io%2fpost%2factive-learning-demo%2f&amp;title=Active%20Learning%20Demo"
         target="_blank" rel="noopener">
        <i class="fab fa-linkedin-in"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=https%3a%2f%2fwood-b.github.io%2fpost%2factive-learning-demo%2f&amp;title=Active%20Learning%20Demo"
         target="_blank" rel="noopener">
        <i class="fab fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=Active%20Learning%20Demo&amp;body=https%3a%2f%2fwood-b.github.io%2fpost%2factive-learning-demo%2f">
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


      </div>
    </div>
    <div class="col-6">
      <div class="split-header-image">
        <img src="/post/active-learning-demo/featured_hu8f0b9e05b19aec9f0cc40148fcb05085_95323_680x500_fill_q90_box_left_2.png" itemprop="image" alt="">
        
      </div>
    </div>
  </div>
</div>

<div class="article-container d-xl-none">
  <h1 itemprop="name">Active Learning Demo</h1>

  

  

<div class="article-metadata">

  
  
  
  <div>
    <span itemscope itemprop="author" itemtype="http://schema.org/Person">
      <span itemprop="name">Brandon M. Wood</span>
    </span>
    
  </div>
  

  <span class="article-date">
    
    <meta content="2020-04-10 12:00:14 -0700 -0700" itemprop="datePublished">
    <time datetime="2020-04-10 12:00:14 -0700 -0700" itemprop="dateModified">
      Apr 10, 2020
    </time>
  </span>
  <span itemscope itemprop="publisher" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Brandon Wood">
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    21 min read
  </span>
  

  
  

  

  
  
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=Active%20Learning%20Demo&amp;url=https%3a%2f%2fwood-b.github.io%2fpost%2factive-learning-demo%2f"
         target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fwood-b.github.io%2fpost%2factive-learning-demo%2f"
         target="_blank" rel="noopener">
        <i class="fab fa-facebook-f"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fwood-b.github.io%2fpost%2factive-learning-demo%2f&amp;title=Active%20Learning%20Demo"
         target="_blank" rel="noopener">
        <i class="fab fa-linkedin-in"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=https%3a%2f%2fwood-b.github.io%2fpost%2factive-learning-demo%2f&amp;title=Active%20Learning%20Demo"
         target="_blank" rel="noopener">
        <i class="fab fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=Active%20Learning%20Demo&amp;body=https%3a%2f%2fwood-b.github.io%2fpost%2factive-learning-demo%2f">
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


  

</div>


  







  









</div>



  <div class="article-container">

    <div class="article-style" itemprop="articleBody">
      <h1 id="active-learning-on-molecular-systems-with-graphdot-xtb-ase-and-scikit-learn">Active Learning on Molecular Systems with GraphDot, xTB, ASE, and scikit-learn</h1>
<p>Original Post: 3/11/2020</p>
<p>Updated: 4/10/2020</p>
<h2 id="introduction">Introduction</h2>
<p>Since the end of my PhD (Aug 2019), I have been interested in combining active learning with quantum calculations to explore configuration space in molecular systems. The goal of this post is to explore active learning on a simple system and to put a few ideas out there for people to think about and expand on. The other reason I wanted to make this post is that I think it is really cool how easily GraphDot/xTB/ASE/scikit-learn can be used together, so I thought I would share by example.</p>
<p>I want to thank <a href="https://crd.lbl.gov/departments/computational-science/ccmc/staff/alvarez-fellows/yu-hang-tang/">Yu-Hang Tang</a> for all the help with the graph kernel, none of this would have been possible otherwise. If you want to learn more about the graph kernel, check out this <a href="http://dx.doi.org/10.1063/1.5078640">publication</a>.</p>
<p>If you have any questions or comments shoot me an email <a href="mailto:bwood@lbl.gov">bwood@lbl.gov</a>.</p>
<h2 id="dependencies">Dependencies</h2>
<p>All dependencies can be pip installed with the exception of xTB, which can now be install with <a href="https://github.com/grimme-lab/xtb">conda</a>, although I used a version I compiled. Additionally, the methods I used from GraphDot require a GPU.</p>
<ul>
<li><a href="https://graphdot.readthedocs.io/en/latest/">GraphDot</a></li>
<li><a href="https://xtb-docs.readthedocs.io/en/latest/contents.html">xTB</a></li>
<li><a href="https://wiki.fysik.dtu.dk/ase/index.html">ASE</a></li>
<li>scikit-learn</li>
<li>Numpy</li>
<li>Matplotlib</li>
<li>tqdm</li>
</ul>
<h1 id="conformations-of-polyethylene">Conformations of Polyethylene</h1>
<p><img src="./pe_tor_rot.png" alt="png"></p>
<h2 id="description-of-the-system">Description of the system</h2>
<p>The toy problem I chose to explore is approximating the energy functional of an ensemble of polyethylene chain conformations. I defined the problem as follows. All chains are made up of 3 monomers — 6 carbon atoms. The rationale for short chains is to keep the degrees of freedom manageable for example purposes. Each chain consists of three C-C-C-C torsion angles ($\phi$$_i$, $\phi$$_j$, $\phi$$_k$) and a conformation is defined as a unique set of the three torsion angles {$\phi$$_i$, $\phi$$_j$, $\phi$$_k$}. I discretized the torsion angle distribution to contain 36 states equally spaced by 10 degrees. The ensemble of conformations is generated by sampling over all of the discrete torsional configurations, so there are ~ $36^3$ conformations — some of these are not unique because of symmetry.</p>
<h2 id="description-of-the-active-learning-algorithm">Description of the active learning algorithm</h2>
<p><img src="./active_learn_scheme.png" alt="png"></p>
<p>The objective is to find a surrogate model for calculating the energy of a chain conformation. Generally speaking, an energy evaluation with density functional theory (DFT) or another level of quantum chemistry is computationally expensive, so if we can generate a reasonable energy prediction (or predict another property of interest) with a machine learning model it saves computational time and expands the systems we can study. In this example, I generate a graph representation of the different conformations using GraphDot and then use a graph kernel with scikit-learn’s Gaussian Process Regression (GPR) to predict energies. I could easily calculate all the conformer energies with xTB; however, if I wanted to use DFT or look at larger systems that would not be possible. As a result, I wanted to implement an active learning strategy. The active learning algorithm I employ is an iterative process where ~1000 conformations are predicted each step, and the 300 conformers with the largest prediction uncertainties are fed back into the training data for the next step. This procedure is intended to ensure that the model sees data that will maximally improve the model each step.</p>
<h2 id="imports">Imports</h2>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">import</span> os
<span style="color:#f92672">import</span> time
<span style="color:#f92672">from</span> tqdm <span style="color:#f92672">import</span> tqdm
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> xtb
<span style="color:#f92672">from</span> xtb <span style="color:#f92672">import</span> GFN2

<span style="color:#f92672">import</span> ase
<span style="color:#f92672">from</span> ase.io <span style="color:#f92672">import</span> read, write
<span style="color:#f92672">from</span> ase.units <span style="color:#f92672">import</span> Hartree
<span style="color:#f92672">from</span> ase.optimize <span style="color:#f92672">import</span> BFGSLineSearch
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> graphdot <span style="color:#f92672">import</span> Graph
<span style="color:#f92672">from</span> graphdot.graph.adjacency <span style="color:#f92672">import</span> AtomicAdjacency
<span style="color:#f92672">from</span> graphdot.kernel.molecular <span style="color:#f92672">import</span> Tang2019MolecularKernel
<span style="color:#f92672">from</span> graphdot.kernel.basekernel <span style="color:#f92672">import</span> KroneckerDelta, SquareExponential, TensorProduct
<span style="color:#f92672">from</span> graphdot.kernel.marginalized <span style="color:#f92672">import</span> MarginalizedGraphKernel
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">%</span>matplotlib inline
<span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> sklearn.gaussian_process <span style="color:#f92672">import</span> GaussianProcessRegressor
<span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> train_test_split
<span style="color:#f92672">from</span> sklearn.metrics <span style="color:#f92672">import</span> r2_score
<span style="color:#f92672">from</span> sklearn.metrics <span style="color:#f92672">import</span> mean_absolute_error
<span style="color:#f92672">from</span> sklearn.metrics <span style="color:#f92672">import</span> mean_squared_error
</code></pre></div><h2 id="generate-dataset-via-torsional-configurations">Generate dataset via torsional configurations</h2>
<p>Torsion angles range from 0 to 360 degrees or depending on the convention from -180 to 180 degrees. For the purposes of this demo I am going to use 0 to 360 because it fits naturally with the convention ASE uses.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">torsion_angles <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>linspace(<span style="color:#ae81ff">0.0</span>, <span style="color:#ae81ff">350.0</span>, num<span style="color:#f92672">=</span><span style="color:#ae81ff">36</span>)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">torsion_angles
</code></pre></div><pre><code>array([  0.,  10.,  20.,  30.,  40.,  50.,  60.,  70.,  80.,  90., 100.,
       110., 120., 130., 140., 150., 160., 170., 180., 190., 200., 210.,
       220., 230., 240., 250., 260., 270., 280., 290., 300., 310., 320.,
       330., 340., 350.])
</code></pre>
<p>Generate an array of all combinations for 3 torsion angles ~46,000
this includes all combinations, not all will be unique because of symmetry</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">tor_combinations <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>zeros((<span style="color:#ae81ff">46656</span>, <span style="color:#ae81ff">3</span>))
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">count <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
<span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> torsion_angles:
    <span style="color:#66d9ef">for</span> j <span style="color:#f92672">in</span> torsion_angles:
        <span style="color:#66d9ef">for</span> k <span style="color:#f92672">in</span> torsion_angles:
            tor_combinations[count] <span style="color:#f92672">=</span> [i, j, k]
            count <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>
</code></pre></div><p>Read in the polyethylene molecule</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">pe_mol <span style="color:#f92672">=</span> read(<span style="color:#e6db74">&#34;pe_n6.xyz&#34;</span>, format<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;xyz&#34;</span>)
</code></pre></div><p>Set the energy calculator</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">pe_mol<span style="color:#f92672">.</span>set_calculator(GFN2())
</code></pre></div><p>Check how long it takes to calculate the energy</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">%</span>time pe_mol<span style="color:#f92672">.</span>get_potential_energy()
</code></pre></div><pre><code>CPU times: user 32.6 ms, sys: 8.23 ms, total: 40.9 ms
Wall time: 25 ms

-543.9429310420319
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">relax <span style="color:#f92672">=</span> BFGSLineSearch(pe_mol)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">relax<span style="color:#f92672">.</span>run(fmax<span style="color:#f92672">=</span><span style="color:#ae81ff">0.05</span>)
</code></pre></div><pre><code>                Step[ FC]     Time          Energy          fmax
*Force-consistent energies used in optimization.
BFGSLineSearch:    0[  0] 11:21:41     -543.942931*       0.7441
BFGSLineSearch:    1[  2] 11:21:41     -544.038490*       0.5208
BFGSLineSearch:    2[  4] 11:21:41     -544.057613*       0.1229
BFGSLineSearch:    3[  6] 11:21:41     -544.058974*       0.0662
BFGSLineSearch:    4[  8] 11:21:41     -544.059370*       0.0572
BFGSLineSearch:    5[ 10] 11:21:41     -544.059850*       0.0372

True
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">pe_mol<span style="color:#f92672">.</span>get_potential_energy()
</code></pre></div><pre><code>-544.0598501831128
</code></pre>
<h2 id="helper-functions-for-generating-data">Helper functions for generating data</h2>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># this function rotates all the torsion angles of the base molecule to the desired angles</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">rotate_all_torsions</span>(base_mol, tor_atoms, tor_angles, rot_indices):
    <span style="color:#75715e"># copy base mol</span>
    rot_mol <span style="color:#f92672">=</span> base_mol<span style="color:#f92672">.</span>copy()
    <span style="color:#75715e"># loop through all the torsion angles in the conformer</span>
    <span style="color:#66d9ef">for</span> i, atom <span style="color:#f92672">in</span> enumerate(tor_atoms):
        rot_mol<span style="color:#f92672">.</span>set_dihedral(a1<span style="color:#f92672">=</span>atom[<span style="color:#ae81ff">0</span>], a2<span style="color:#f92672">=</span>atom[<span style="color:#ae81ff">1</span>], a3<span style="color:#f92672">=</span>atom[<span style="color:#ae81ff">2</span>], a4<span style="color:#f92672">=</span>atom[<span style="color:#ae81ff">3</span>], 
                             angle<span style="color:#f92672">=</span>tor_angles[i], indices<span style="color:#f92672">=</span>rot_indices[i])
    <span style="color:#66d9ef">return</span> rot_mol
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># this function generates all the rotated molecules and calculates their energy</span>
<span style="color:#75715e"># additionally an energy cutoff of 1 eV is imposed</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">generate_data</span>(base_mol, tors_list, tor_atoms, rot_indicies, sample_num):
    mol_list <span style="color:#f92672">=</span> []
    <span style="color:#66d9ef">with</span> tqdm(total<span style="color:#f92672">=</span>sample_num) <span style="color:#66d9ef">as</span> pbar:
        <span style="color:#66d9ef">for</span> angles <span style="color:#f92672">in</span> tors_list:
            rot_mol <span style="color:#f92672">=</span> rotate_all_torsions(base_mol, tor_atoms, angles, rot_indicies)
            rot_mol<span style="color:#f92672">.</span>set_calculator(GFN2())
            r_energy <span style="color:#f92672">=</span> rot_mol<span style="color:#f92672">.</span>get_potential_energy()
            <span style="color:#75715e"># energy cutoff of -543.0 eV</span>
            <span style="color:#66d9ef">if</span> r_energy <span style="color:#f92672">&lt;</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">543.0</span>:
                mol_list<span style="color:#f92672">.</span>append(rot_mol)
                pbar<span style="color:#f92672">.</span>update(<span style="color:#ae81ff">1</span>)
            <span style="color:#66d9ef">else</span>:
                <span style="color:#66d9ef">continue</span>
            <span style="color:#66d9ef">if</span> len(mol_list) <span style="color:#f92672">==</span> sample_num:
                <span style="color:#66d9ef">break</span>
            <span style="color:#66d9ef">else</span>:
                <span style="color:#66d9ef">continue</span>
    <span style="color:#66d9ef">return</span> mol_list
</code></pre></div><h2 id="specify-atoms-involved-in-each-torsion-angle">Specify atoms involved in each torsion angle</h2>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># these are specific for this particular molecule and xyz file ordering</span>
pe_n6_tor_atoms <span style="color:#f92672">=</span> [[<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">8</span>], [<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">11</span>], [<span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">11</span>, <span style="color:#ae81ff">14</span>]]
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># these are specific for this particular molecule and xyz file ordering</span>
pe_n6_tor_indices<span style="color:#f92672">=</span>[[<span style="color:#ae81ff">8</span>,<span style="color:#ae81ff">9</span>,<span style="color:#ae81ff">10</span>,<span style="color:#ae81ff">11</span>,<span style="color:#ae81ff">12</span>,<span style="color:#ae81ff">13</span>,<span style="color:#ae81ff">14</span>,<span style="color:#ae81ff">15</span>,<span style="color:#ae81ff">16</span>,<span style="color:#ae81ff">17</span>,<span style="color:#ae81ff">18</span>,<span style="color:#ae81ff">19</span>], [<span style="color:#ae81ff">11</span>,<span style="color:#ae81ff">12</span>,<span style="color:#ae81ff">13</span>,<span style="color:#ae81ff">14</span>,<span style="color:#ae81ff">15</span>,<span style="color:#ae81ff">16</span>,<span style="color:#ae81ff">17</span>,<span style="color:#ae81ff">18</span>,<span style="color:#ae81ff">19</span>], [<span style="color:#ae81ff">14</span>,<span style="color:#ae81ff">15</span>,<span style="color:#ae81ff">16</span>,<span style="color:#ae81ff">17</span>,<span style="color:#ae81ff">18</span>,<span style="color:#ae81ff">19</span>]]
</code></pre></div><h2 id="generate-and-write-data">Generate and write data</h2>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># shuffle torsion combinations</span>
random_tors <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>copy(tor_combinations)
np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>shuffle(random_tors)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># %time mol_list = generate_data(pe_mol, random_tors, pe_n6_tor_atoms, pe_n6_tor_indices, 13000)</span>
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># this took 6 mins to run</span>
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># write all 13k ase atom objects into an xyz file</span>
<span style="color:#75715e"># write(&#34;./data/pe_13k_dataset.xyz&#34;, images=mol_list, format=&#34;xyz&#34;)</span>
</code></pre></div><p><strong>Comment on calculating all the energies at once</strong>: Ideally, I would calculate energies on the fly in the active learning loop; however, for simplicity and because of the energy cutoff I am using I did everything at once. If I had done energy calculations in the active learning loop I would have saved myself 7000 energy evaluations — which can save a substantial amount of computational time depending on the method used.</p>
<h2 id="read-molecule-data-and-generate-graphs">Read molecule data and generate graphs</h2>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">%</span>time mol_list <span style="color:#f92672">=</span> read(<span style="color:#e6db74">&#34;./data/pe_13k_dataset.xyz&#34;</span>, index<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;:&#34;</span>, format<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;xyz&#34;</span>)
</code></pre></div><pre><code>CPU times: user 5.53 s, sys: 259 ms, total: 5.78 s
Wall time: 5.77 s
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># parameter for generating graphs</span>
adj <span style="color:#f92672">=</span> AtomicAdjacency(shape<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;tent2&#39;</span>, zoom<span style="color:#f92672">=</span><span style="color:#ae81ff">2.0</span>)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># this function gets the input graphs and target energies</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_xy_data</span>(mols, adj):
    <span style="color:#75715e"># shuffle the mols again</span>
    random_mols <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>copy(mols)
    np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>shuffle(random_mols)
    energy_array <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([mol<span style="color:#f92672">.</span>get_potential_energy() <span style="color:#66d9ef">for</span> mol <span style="color:#f92672">in</span> mols])
    graph_array <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([Graph<span style="color:#f92672">.</span>from_ase(mol, adjacency<span style="color:#f92672">=</span>adj) <span style="color:#66d9ef">for</span> mol <span style="color:#f92672">in</span> mols])
    <span style="color:#66d9ef">return</span> graph_array, energy_array
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">%</span>time graphs, energies <span style="color:#f92672">=</span> get_xy_data(mol_list, adj)
</code></pre></div><pre><code>CPU times: user 47.3 s, sys: 367 ms, total: 47.6 s
Wall time: 47.6 s
</code></pre>
<h2 id="define-the-graph-kernel">Define the graph kernel</h2>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">mol_kernel <span style="color:#f92672">=</span> Tang2019MolecularKernel(edge_length_scale<span style="color:#f92672">=</span><span style="color:#ae81ff">0.02</span>, stopping_probability<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>)
</code></pre></div><p>In order to use scikit-learn&rsquo;s GPR we need to define a MarginalizedGraphKernel object. The kernel defined below is essentially the same as the Tang2019MolecularKernel. I double check that assumption below.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">kernel <span style="color:#f92672">=</span> MarginalizedGraphKernel(node_kernel<span style="color:#f92672">=</span>TensorProduct(element<span style="color:#f92672">=</span>KroneckerDelta(<span style="color:#ae81ff">0.2</span>)), 
                                 edge_kernel<span style="color:#f92672">=</span>TensorProduct(length<span style="color:#f92672">=</span>SquareExponential(<span style="color:#ae81ff">0.02</span>)), 
                                 q<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>)
</code></pre></div><h2 id="check-graphs-and-visualize-similarity-matrix">Check graphs and visualize similarity matrix</h2>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">try_graphs <span style="color:#f92672">=</span> graphs[:<span style="color:#ae81ff">500</span>]
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">try_energies <span style="color:#f92672">=</span> energies[:<span style="color:#ae81ff">500</span>]
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">R_mol <span style="color:#f92672">=</span> mol_kernel(try_graphs, lmin<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">.</span>astype(np<span style="color:#f92672">.</span>float)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">D_mol <span style="color:#f92672">=</span> R_mol<span style="color:#f92672">.</span>diagonal()<span style="color:#f92672">**-</span><span style="color:#ae81ff">0.5</span>
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">K_mol <span style="color:#f92672">=</span> D_mol[:, None] <span style="color:#f92672">*</span> R_mol <span style="color:#f92672">*</span> D_mol[None, :]
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># visualize the similarity matrix</span>
plt<span style="color:#f92672">.</span>imshow(K_mol)
</code></pre></div><pre><code>&lt;matplotlib.image.AxesImage at 0x2aab24d429d0&gt;
</code></pre>
<p><img src="./active_learning_demo_7_write_files_60_1.png" alt="png"></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">K_mol<span style="color:#f92672">.</span>max()
</code></pre></div><pre><code>1.000000173664869
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">K_mol<span style="color:#f92672">.</span>min()
</code></pre></div><pre><code>0.8706799071173481
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">R <span style="color:#f92672">=</span> kernel(try_graphs, lmin<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">.</span>astype(np<span style="color:#f92672">.</span>float)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">D <span style="color:#f92672">=</span> R<span style="color:#f92672">.</span>diagonal()<span style="color:#f92672">**-</span><span style="color:#ae81ff">0.5</span>
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">K <span style="color:#f92672">=</span> D[:, None] <span style="color:#f92672">*</span> R <span style="color:#f92672">*</span> D[None, :]
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># visualize the similarity matrix</span>
plt<span style="color:#f92672">.</span>imshow(K)
</code></pre></div><pre><code>&lt;matplotlib.image.AxesImage at 0x2aab24de3d10&gt;
</code></pre>
<p><img src="./active_learning_demo_7_write_files_66_1.png" alt="png"></p>
<p>The yellow diagonal represents when conformers are compared to themselves</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">K<span style="color:#f92672">.</span>max()
</code></pre></div><pre><code>1.000000249324106
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">K<span style="color:#f92672">.</span>min()
</code></pre></div><pre><code>0.8706799071173481
</code></pre>
<p>The minimum similarity is fairly high, which isn&rsquo;t that surprising considering I am comparing the same molecule just with different torsional rotations.</p>
<h2 id="calculate-a-specific-torsion-potential-for-benchmarking">Calculate a specific torsion potential for benchmarking</h2>
<p>To track how the model improves at each step, I generate the inputs and targets for a specific torsion potential to benchmark against. Arbitrarily, I chose the central torsion angle $\phi$$_j$, leaving $\phi$$_i$ and $\phi$$_k$ fixed. In the future, it would be nice to guarantee these benchmarking data points were held out of the training set, right now, they may or may not be included.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_torsion_pot</span>(base_mol, tor_atoms, tor_angles, rot_indices, adj):
    tor_graphs <span style="color:#f92672">=</span> []
    tor_energies <span style="color:#f92672">=</span> []
    <span style="color:#66d9ef">for</span> angle <span style="color:#f92672">in</span> tor_angles:
        rot_mol <span style="color:#f92672">=</span> rotate_all_torsions(base_mol, tor_atoms, [angle], rot_indices)
        rot_mol<span style="color:#f92672">.</span>set_calculator(GFN2())
        tor_energies<span style="color:#f92672">.</span>append(rot_mol<span style="color:#f92672">.</span>get_potential_energy())
        tor_graphs<span style="color:#f92672">.</span>append(Graph<span style="color:#f92672">.</span>from_ase(rot_mol, adjacency<span style="color:#f92672">=</span>adj))
    <span style="color:#66d9ef">return</span> tor_energies, tor_graphs
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># these are specific for this particular molecule and xyz file ordering</span>
pe_t2_tor_atoms <span style="color:#f92672">=</span> [[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">11</span>]]
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># these are specific for this particular molecule and xyz file ordering</span>
pe_t2_tor_indices<span style="color:#f92672">=</span>[[<span style="color:#ae81ff">11</span>,<span style="color:#ae81ff">12</span>,<span style="color:#ae81ff">13</span>,<span style="color:#ae81ff">14</span>,<span style="color:#ae81ff">15</span>,<span style="color:#ae81ff">16</span>,<span style="color:#ae81ff">17</span>,<span style="color:#ae81ff">18</span>,<span style="color:#ae81ff">19</span>]]
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">tor_pot_angles <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>linspace(<span style="color:#ae81ff">0.0</span>, <span style="color:#ae81ff">360.0</span>, num<span style="color:#f92672">=</span><span style="color:#ae81ff">37</span>)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">tor_pot_sp_energies, tor_pot_graphs <span style="color:#f92672">=</span> get_torsion_pot(pe_mol, pe_t2_tor_atoms, tor_pot_angles, pe_t2_tor_indices, adj)
</code></pre></div><h2 id="active-learning-object">Active learning object</h2>
<p>This is a simple class to help organize the active learning loop. ActiveGPR initializes a scikit-learn GPR model and has train, explore, updata_data, and calc_metrics methods.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">ActiveGPR</span>():
    <span style="color:#66d9ef">def</span> __init__(self, kernel, X_train, y_train, X_val, y_val, X_tor_pot):
        self<span style="color:#f92672">.</span>X_train <span style="color:#f92672">=</span> X_train
        self<span style="color:#f92672">.</span>y_train <span style="color:#f92672">=</span> y_train
        self<span style="color:#f92672">.</span>X_val <span style="color:#f92672">=</span> X_val
        self<span style="color:#f92672">.</span>y_val <span style="color:#f92672">=</span> y_val
        self<span style="color:#f92672">.</span>X_tor_pot <span style="color:#f92672">=</span> X_tor_pot
        self<span style="color:#f92672">.</span>uncertain <span style="color:#f92672">=</span> None
        <span style="color:#75715e"># the default alpha value needs to be adjusted and </span>
        <span style="color:#75715e"># normalize y is turned on because our energies do not have a mean of zero</span>
        self<span style="color:#f92672">.</span>gpr <span style="color:#f92672">=</span> GaussianProcessRegressor(kernel<span style="color:#f92672">=</span>kernel, optimizer<span style="color:#f92672">=</span>None, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.02</span>, normalize_y<span style="color:#f92672">=</span>True)
        self<span style="color:#f92672">.</span>metrics <span style="color:#f92672">=</span> {<span style="color:#e6db74">&#34;step&#34;</span>: [], <span style="color:#e6db74">&#34;rmse&#34;</span>: [], <span style="color:#e6db74">&#34;mae&#34;</span>: [], <span style="color:#e6db74">&#34;r2&#34;</span>: []}
        self<span style="color:#f92672">.</span>pred_pot <span style="color:#f92672">=</span> []
        self<span style="color:#f92672">.</span>step <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
        
    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">train</span>(self):
        self<span style="color:#f92672">.</span>gpr<span style="color:#f92672">.</span>fit(self<span style="color:#f92672">.</span>X_train, self<span style="color:#f92672">.</span>y_train);
        self<span style="color:#f92672">.</span>calc_metrics(self<span style="color:#f92672">.</span>X_val, self<span style="color:#f92672">.</span>y_val)
        self<span style="color:#f92672">.</span>pred_pot<span style="color:#f92672">.</span>append(self<span style="color:#f92672">.</span>gpr<span style="color:#f92672">.</span>predict(self<span style="color:#f92672">.</span>X_tor_pot, return_std<span style="color:#f92672">=</span>True))
        self<span style="color:#f92672">.</span>step <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>
    
    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">explore</span>(self, X_new, sample_num<span style="color:#f92672">=</span><span style="color:#ae81ff">300</span>):
        y_pred, y_std <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>gpr<span style="color:#f92672">.</span>predict(X_new, return_std<span style="color:#f92672">=</span>True)
        <span style="color:#75715e"># np.argsort sorts from min to max so selecting from the end of array gives</span>
        <span style="color:#75715e"># the max uncertainty</span>
        uncertain_indexes <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>argsort(y_std)
        self<span style="color:#f92672">.</span>uncertain <span style="color:#f92672">=</span> uncertain_indexes[(len(uncertain_indexes) <span style="color:#f92672">-</span> sample_num):]

    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">update_data</span>(self, X, y):
        X_new <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(X)[self<span style="color:#f92672">.</span>uncertain]
        y_new <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(y)[self<span style="color:#f92672">.</span>uncertain]
        X_train <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>concatenate((self<span style="color:#f92672">.</span>X_train, X_new), axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
        y_train <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>concatenate((self<span style="color:#f92672">.</span>y_train, y_new), axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
        <span style="color:#75715e"># shuffle data</span>
        shuffle_ind <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>arange(len(X_train))
        np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>shuffle(shuffle_ind)
        self<span style="color:#f92672">.</span>X_train <span style="color:#f92672">=</span> X_train[shuffle_ind]
        self<span style="color:#f92672">.</span>y_train <span style="color:#f92672">=</span> y_train[shuffle_ind]
        
    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">calc_metrics</span>(self, X, y):
        y_pred <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>gpr<span style="color:#f92672">.</span>predict(X)
        r2 <span style="color:#f92672">=</span> r2_score(y, y_pred)
        rmse <span style="color:#f92672">=</span> mean_squared_error(y, y_pred, squared<span style="color:#f92672">=</span>False) 
        mae <span style="color:#f92672">=</span> mean_absolute_error(y, y_pred)
        self<span style="color:#f92672">.</span>metrics[<span style="color:#e6db74">&#34;rmse&#34;</span>]<span style="color:#f92672">.</span>append(rmse)
        self<span style="color:#f92672">.</span>metrics[<span style="color:#e6db74">&#34;mae&#34;</span>]<span style="color:#f92672">.</span>append(mae)
        self<span style="color:#f92672">.</span>metrics[<span style="color:#e6db74">&#34;r2&#34;</span>]<span style="color:#f92672">.</span>append(r2)
</code></pre></div><h2 id="active-learning-loop">Active learning loop</h2>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># define train, val, and test sets</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">train_val_test_split</span>(energies, graphs, val_size, test_size, initial_size, active_size):
    X_test <span style="color:#f92672">=</span> graphs[:test_size]
    y_test <span style="color:#f92672">=</span> energies[:test_size]
    X_val <span style="color:#f92672">=</span> graphs[test_size:(test_size <span style="color:#f92672">+</span> val_size)]
    y_val <span style="color:#f92672">=</span> energies[test_size:(test_size <span style="color:#f92672">+</span> val_size)]
    <span style="color:#75715e"># returns the train set</span>
    train_size <span style="color:#f92672">=</span> int(len(energies) <span style="color:#f92672">-</span> (test_size <span style="color:#f92672">+</span> val_size))
    splits <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>arange(initial_size, train_size, active_size)
    X_train_set <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>split(graphs[(test_size <span style="color:#f92672">+</span> val_size):], splits, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
    y_train_set <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>split(energies[(test_size <span style="color:#f92672">+</span> val_size):], splits, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
    <span style="color:#66d9ef">return</span> X_train_set, y_train_set, X_val, y_val, X_test, y_test
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">X_train, y_train, X_val, y_val, X_test, y_test <span style="color:#f92672">=</span> train_val_test_split(energies, graphs, <span style="color:#ae81ff">1000</span>, <span style="color:#ae81ff">1000</span>, <span style="color:#ae81ff">1000</span>, <span style="color:#ae81ff">1000</span>)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">pe_gpr <span style="color:#f92672">=</span> ActiveGPR(kernel, X_train[<span style="color:#ae81ff">0</span>], y_train[<span style="color:#ae81ff">0</span>], X_val, y_val, tor_pot_graphs)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># active learning loop</span>
active_steps <span style="color:#f92672">=</span> range(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">11</span>)
<span style="color:#66d9ef">for</span> step <span style="color:#f92672">in</span> active_steps:
    s_time <span style="color:#f92672">=</span> time<span style="color:#f92672">.</span>perf_counter()
    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Learning Step: {s}&#34;</span><span style="color:#f92672">.</span>format(s<span style="color:#f92672">=</span>pe_gpr<span style="color:#f92672">.</span>step))
    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Training Data Size: {d}&#34;</span><span style="color:#f92672">.</span>format(d<span style="color:#f92672">=</span>len(pe_gpr<span style="color:#f92672">.</span>X_train)))
    
    pe_gpr<span style="color:#f92672">.</span>train()
    <span style="color:#75715e">#X_new, y_new = generate_data(pe_mol, train_tor_list[step + 1], pe_n6_tor_atoms, pe_n6_tor_indices, adj, 1000)</span>
    <span style="color:#66d9ef">if</span> step <span style="color:#f92672">!=</span> len(active_steps) <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>:
        X_new <span style="color:#f92672">=</span> X_train[step <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>]
        y_new <span style="color:#f92672">=</span> y_train[step <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>]
        pe_gpr<span style="color:#f92672">.</span>explore(X_new)
        pe_gpr<span style="color:#f92672">.</span>update_data(X_new, y_new)
    
    e_time <span style="color:#f92672">=</span> time<span style="color:#f92672">.</span>perf_counter()
    
    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;MAE: {mae:0.3f}&#34;</span><span style="color:#f92672">.</span>format(mae<span style="color:#f92672">=</span>pe_gpr<span style="color:#f92672">.</span>metrics[<span style="color:#e6db74">&#34;mae&#34;</span>][step]))
    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;RMSE: {rmse:0.3f}&#34;</span><span style="color:#f92672">.</span>format(rmse<span style="color:#f92672">=</span>pe_gpr<span style="color:#f92672">.</span>metrics[<span style="color:#e6db74">&#34;rmse&#34;</span>][step]))
    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;R-squared: {r2:0.5f}&#34;</span><span style="color:#f92672">.</span>format(r2<span style="color:#f92672">=</span>pe_gpr<span style="color:#f92672">.</span>metrics[<span style="color:#e6db74">&#34;r2&#34;</span>][step]))
    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Step Time(s): {t:0.2f}&#34;</span><span style="color:#f92672">.</span>format(t<span style="color:#f92672">=</span>(e_time <span style="color:#f92672">-</span> s_time)))
    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;---------- End of Step ----------&#34;</span>)
</code></pre></div><pre><code>Learning Step: 0
Training Data Size: 1000
      0.5 ms on generating jobs
      0.2 ms on creating output buffer
      0.7 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
      8.9 ms on code generation
    190.7 ms on JIT
      1.1 ms on calculating launch configuration
      3.8 ms on GPU kernel execution
    205.7 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
      0.8 ms on generating jobs
      0.3 ms on creating output buffer
      7.5 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
     15.8 ms on code generation
    179.1 ms on JIT
      2.3 ms on calculating launch configuration
      5.1 ms on GPU kernel execution
    210.3 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
MAE: 0.018
RMSE: 0.029
R-squared: 0.98452
Step Time(s): 13.47
---------- End of Step ----------
Learning Step: 1
Training Data Size: 1300
      0.5 ms on generating jobs
      0.3 ms on creating output buffer
      0.7 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
      8.9 ms on code generation
    192.6 ms on JIT
      0.5 ms on calculating launch configuration
      2.1 ms on GPU kernel execution
    205.1 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
      0.5 ms on generating jobs
      0.3 ms on creating output buffer
     13.5 ms on transferring graphs to GPU
      0.2 ms on allocate global job counter
     12.2 ms on code generation
    189.0 ms on JIT
      2.6 ms on calculating launch configuration
      5.0 ms on GPU kernel execution
    222.8 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
MAE: 0.014
RMSE: 0.022
R-squared: 0.99173
Step Time(s): 16.96
---------- End of Step ----------
Learning Step: 2
Training Data Size: 1600
      0.5 ms on generating jobs
      0.3 ms on creating output buffer
      0.7 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
      8.7 ms on code generation
    188.6 ms on JIT
      0.5 ms on calculating launch configuration
      1.7 ms on GPU kernel execution
    200.6 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
      0.6 ms on generating jobs
      0.3 ms on creating output buffer
     12.7 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
     12.5 ms on code generation
    186.0 ms on JIT
      2.1 ms on calculating launch configuration
      5.2 ms on GPU kernel execution
    219.0 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
MAE: 0.011
RMSE: 0.017
R-squared: 0.99502
Step Time(s): 22.28
---------- End of Step ----------
Learning Step: 3
Training Data Size: 1900
      0.5 ms on generating jobs
      0.3 ms on creating output buffer
      0.7 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
      8.8 ms on code generation
    191.2 ms on JIT
      0.5 ms on calculating launch configuration
      1.9 ms on GPU kernel execution
    203.3 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
      0.6 ms on generating jobs
      0.3 ms on creating output buffer
     15.4 ms on transferring graphs to GPU
      0.3 ms on allocate global job counter
     13.5 ms on code generation
    186.4 ms on JIT
      3.1 ms on calculating launch configuration
      5.6 ms on GPU kernel execution
    224.6 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
MAE: 0.010
RMSE: 0.015
R-squared: 0.99611
Step Time(s): 28.16
---------- End of Step ----------
Learning Step: 4
Training Data Size: 2200
      0.5 ms on generating jobs
      0.3 ms on creating output buffer
      0.8 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
      9.0 ms on code generation
    187.0 ms on JIT
      0.5 ms on calculating launch configuration
      1.8 ms on GPU kernel execution
    199.5 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
      0.5 ms on generating jobs
      0.2 ms on creating output buffer
     12.6 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
     12.4 ms on code generation
    188.6 ms on JIT
      2.3 ms on calculating launch configuration
      5.3 ms on GPU kernel execution
    221.6 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
MAE: 0.009
RMSE: 0.013
R-squared: 0.99690
Step Time(s): 34.71
---------- End of Step ----------
Learning Step: 5
Training Data Size: 2500
      0.5 ms on generating jobs
      0.4 ms on creating output buffer
      0.7 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
      8.7 ms on code generation
    183.8 ms on JIT
      0.5 ms on calculating launch configuration
      1.8 ms on GPU kernel execution
    195.8 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
      0.6 ms on generating jobs
      0.2 ms on creating output buffer
     13.4 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
     12.2 ms on code generation
    155.7 ms on JIT
      2.3 ms on calculating launch configuration
      5.2 ms on GPU kernel execution
    189.2 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
MAE: 0.008
RMSE: 0.012
R-squared: 0.99732
Step Time(s): 42.01
---------- End of Step ----------
Learning Step: 6
Training Data Size: 2800
      0.5 ms on generating jobs
      0.3 ms on creating output buffer
      0.7 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
      8.6 ms on code generation
    182.4 ms on JIT
      0.5 ms on calculating launch configuration
      1.7 ms on GPU kernel execution
    194.2 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
      0.5 ms on generating jobs
      0.3 ms on creating output buffer
     13.1 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
     12.3 ms on code generation
    186.8 ms on JIT
      2.3 ms on calculating launch configuration
      5.4 ms on GPU kernel execution
    220.4 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
MAE: 0.007
RMSE: 0.011
R-squared: 0.99783
Step Time(s): 50.00
---------- End of Step ----------
Learning Step: 7
Training Data Size: 3100
      0.6 ms on generating jobs
      0.4 ms on creating output buffer
      0.8 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
      9.0 ms on code generation
    172.8 ms on JIT
      0.5 ms on calculating launch configuration
      1.7 ms on GPU kernel execution
    185.2 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
      0.6 ms on generating jobs
      0.3 ms on creating output buffer
     13.9 ms on transferring graphs to GPU
      0.2 ms on allocate global job counter
     13.2 ms on code generation
    190.5 ms on JIT
      2.2 ms on calculating launch configuration
      5.0 ms on GPU kernel execution
    225.4 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
MAE: 0.007
RMSE: 0.010
R-squared: 0.99812
Step Time(s): 58.98
---------- End of Step ----------
Learning Step: 8
Training Data Size: 3400
      0.6 ms on generating jobs
      0.3 ms on creating output buffer
      0.8 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
      8.7 ms on code generation
    173.3 ms on JIT
      0.5 ms on calculating launch configuration
      1.8 ms on GPU kernel execution
    185.4 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
      0.5 ms on generating jobs
      0.3 ms on creating output buffer
     14.1 ms on transferring graphs to GPU
      0.2 ms on allocate global job counter
     12.6 ms on code generation
    188.5 ms on JIT
      2.3 ms on calculating launch configuration
      5.2 ms on GPU kernel execution
    223.3 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
MAE: 0.007
RMSE: 0.009
R-squared: 0.99849
Step Time(s): 68.16
---------- End of Step ----------
Learning Step: 9
Training Data Size: 3700
      0.5 ms on generating jobs
      0.4 ms on creating output buffer
      0.7 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
      8.8 ms on code generation
    166.4 ms on JIT
      0.5 ms on calculating launch configuration
      1.8 ms on GPU kernel execution
    178.5 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
      0.8 ms on generating jobs
      0.3 ms on creating output buffer
     13.6 ms on transferring graphs to GPU
      0.2 ms on allocate global job counter
     17.0 ms on code generation
    190.8 ms on JIT
      2.4 ms on calculating launch configuration
      5.0 ms on GPU kernel execution
    229.4 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
MAE: 0.006
RMSE: 0.009
R-squared: 0.99859
Step Time(s): 77.91
---------- End of Step ----------
Learning Step: 10
Training Data Size: 4000
      0.5 ms on generating jobs
      0.5 ms on creating output buffer
      0.8 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
      8.9 ms on code generation
    163.4 ms on JIT
      0.5 ms on calculating launch configuration
      1.7 ms on GPU kernel execution
    175.7 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
MAE: 0.006
RMSE: 0.008
R-squared: 0.99879
Step Time(s): 73.67
---------- End of Step ----------
</code></pre>
<h2 id="plot-validation-mae-and-rmse">Plot Validation MAE and RMSE</h2>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">fig <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>figure()
ax <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">111</span>)
ax<span style="color:#f92672">.</span>plot(range(<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">11</span>), pe_gpr<span style="color:#f92672">.</span>metrics[<span style="color:#e6db74">&#34;mae&#34;</span>])
ax<span style="color:#f92672">.</span>set_xlabel(<span style="color:#e6db74">&#34;Active Learning Step&#34;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">15</span>)
ax<span style="color:#f92672">.</span>set_ylabel(<span style="color:#e6db74">&#34;MAE</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">(eV)&#34;</span>, rotation<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>, labelpad<span style="color:#f92672">=</span><span style="color:#ae81ff">30</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">15</span>)
<span style="color:#75715e">#ax.set_ylim(0.00, 0.14)</span>
ax<span style="color:#f92672">.</span>spines[<span style="color:#e6db74">&#34;right&#34;</span>]<span style="color:#f92672">.</span>set_visible(False)
ax<span style="color:#f92672">.</span>spines[<span style="color:#e6db74">&#34;top&#34;</span>]<span style="color:#f92672">.</span>set_visible(False)
<span style="color:#75715e">#plt.title(&#34;&#34;, fontsize=15)</span>
<span style="color:#75715e">#ax.legend([], frameon=False)</span>
</code></pre></div><p><img src="./active_learning_demo_7_write_files_87_0.png" alt="png"></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">fig <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>figure()
ax <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">111</span>)
ax<span style="color:#f92672">.</span>plot(range(<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">11</span>), pe_gpr<span style="color:#f92672">.</span>metrics[<span style="color:#e6db74">&#34;rmse&#34;</span>], c<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;C1&#34;</span>)
ax<span style="color:#f92672">.</span>set_xlabel(<span style="color:#e6db74">&#34;Active Learning Step&#34;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">15</span>)
ax<span style="color:#f92672">.</span>set_ylabel(<span style="color:#e6db74">&#34;RMSE</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">(eV)&#34;</span>, rotation<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>, labelpad<span style="color:#f92672">=</span><span style="color:#ae81ff">30</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">15</span>)
<span style="color:#75715e">#ax.set_ylim(0.00, 0.14)</span>
ax<span style="color:#f92672">.</span>spines[<span style="color:#e6db74">&#34;right&#34;</span>]<span style="color:#f92672">.</span>set_visible(False)
ax<span style="color:#f92672">.</span>spines[<span style="color:#e6db74">&#34;top&#34;</span>]<span style="color:#f92672">.</span>set_visible(False)
<span style="color:#75715e">#plt.title(&#34;&#34;, fontsize=15)</span>
<span style="color:#75715e">#ax.legend([], frameon=False)</span>
</code></pre></div><p><img src="./active_learning_demo_7_write_files_88_0.png" alt="png"></p>
<h2 id="test-mae-and-rmse">Test MAE and RMSE</h2>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">pe_gpr<span style="color:#f92672">.</span>calc_metrics(X_test, y_test)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;MAE: {mae:0.3f}&#34;</span><span style="color:#f92672">.</span>format(mae<span style="color:#f92672">=</span>pe_gpr<span style="color:#f92672">.</span>metrics[<span style="color:#e6db74">&#34;mae&#34;</span>][<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]))
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;RMSE: {rmse:0.3f}&#34;</span><span style="color:#f92672">.</span>format(rmse<span style="color:#f92672">=</span>pe_gpr<span style="color:#f92672">.</span>metrics[<span style="color:#e6db74">&#34;rmse&#34;</span>][<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]))
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;R-squared: {r2:0.5f}&#34;</span><span style="color:#f92672">.</span>format(r2<span style="color:#f92672">=</span>pe_gpr<span style="color:#f92672">.</span>metrics[<span style="color:#e6db74">&#34;r2&#34;</span>][<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]))
</code></pre></div><pre><code>MAE: 0.006
RMSE: 0.008
R-squared: 0.99888
</code></pre>
<p>The final MAE and RMSE values are encouraging. For reference, chemical accuracy — the requirement to make useful chemical predictions — is generally considered to be 1 kcal/mol or ~ 0.04 eV. The final MAE value of 0.006 eV is well within that range, which is great, but there are a few caveats. For one, I used an energy cutoff of 1 eV so that limited the overall energy distribution. It would be interesting to compare my results to randomly guessing energy values within the 1 eV window. Additionally, torsional energy barriers can be low (&lt; 0.025 eV), as a result we would hope that we could resolve those features in the potential energy surface.</p>
<p><strong>Comment on the coefficient of determination ($R^2$):</strong> The interpretation of $R^2$ in this context is not entirely clear to me, but it says something about the amount of variance accounted for by the GPR model. It also tells us that our model is better than a model that always predicts the mean value of y regardless of the input features ($R^2$ = 0). <strong>TL;DR</strong> $R^2$ values increase with each active learning step indicating the model is improving.</p>
<h2 id="predicting-torsion-potentials">Predicting torsion potentials</h2>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># torsion potentials are displayed using relative energies</span>
rel_sp_energies <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(tor_pot_sp_energies) <span style="color:#f92672">-</span> min(tor_pot_sp_energies)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">rel_tor_predict <span style="color:#f92672">=</span> [array[<span style="color:#ae81ff">0</span>] <span style="color:#f92672">-</span> min(array[<span style="color:#ae81ff">0</span>]) <span style="color:#66d9ef">for</span> array <span style="color:#f92672">in</span> pe_gpr<span style="color:#f92672">.</span>pred_pot]
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># propagate the error (energy – min(energy)) </span>
tor_std_prop <span style="color:#f92672">=</span> []
<span style="color:#66d9ef">for</span> array <span style="color:#f92672">in</span> pe_gpr<span style="color:#f92672">.</span>pred_pot:
    min_index <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>argmin(array[<span style="color:#ae81ff">0</span>])
    err_prop <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>sqrt(np<span style="color:#f92672">.</span>power(array[<span style="color:#ae81ff">1</span>], <span style="color:#ae81ff">2</span>) <span style="color:#f92672">+</span> np<span style="color:#f92672">.</span>power(array[<span style="color:#ae81ff">1</span>][min_index], <span style="color:#ae81ff">2</span>))
    tor_std_prop<span style="color:#f92672">.</span>append(err_prop)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">tor_pot_plot</span>(rel_energy, rel_predict, std, color, ylim<span style="color:#f92672">=</span>(<span style="color:#f92672">-</span><span style="color:#ae81ff">0.2</span>, <span style="color:#ae81ff">0.45</span>)):
    fig <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>figure()
    ax <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">111</span>)
    ax<span style="color:#f92672">.</span>plot(tor_pot_angles, rel_energy)
    ax<span style="color:#f92672">.</span>plot(tor_pot_angles, rel_predict, <span style="color:#e6db74">&#34;o&#34;</span>, c<span style="color:#f92672">=</span>color)
    <span style="color:#75715e">#ax.errorbar(tor_pot_angles, rel_predict, yerr=std, fmt=&#34;o&#34;, c=color)</span>
    ax<span style="color:#f92672">.</span>fill_between(tor_pot_angles, rel_predict <span style="color:#f92672">-</span> std, rel_predict <span style="color:#f92672">+</span> std, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.125</span>)
    ax<span style="color:#f92672">.</span>set_xlabel(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#34;Torsion Angle ($\degree$)&#34;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">15</span>)
    ax<span style="color:#f92672">.</span>set_ylabel(<span style="color:#e6db74">&#34;Relative</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Energy (eV)&#34;</span>, rotation<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>, labelpad<span style="color:#f92672">=</span><span style="color:#ae81ff">50</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">15</span>)
    ax<span style="color:#f92672">.</span>set_ylim(ylim)
    ax<span style="color:#f92672">.</span>set_yticks([<span style="color:#ae81ff">0.00</span>, <span style="color:#ae81ff">0.15</span>, <span style="color:#ae81ff">0.35</span>])
    ax<span style="color:#f92672">.</span>set_xticks([<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">180</span>, <span style="color:#ae81ff">360</span>])
    ax<span style="color:#f92672">.</span>spines[<span style="color:#e6db74">&#34;right&#34;</span>]<span style="color:#f92672">.</span>set_visible(False)
    ax<span style="color:#f92672">.</span>spines[<span style="color:#e6db74">&#34;top&#34;</span>]<span style="color:#f92672">.</span>set_visible(False)
    ax<span style="color:#f92672">.</span>legend([<span style="color:#e6db74">&#34;True&#34;</span>, <span style="color:#e6db74">&#34;Predict&#34;</span>, <span style="color:#e6db74">&#34;Predict Uncertainty&#34;</span>], loc<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;upper right&#34;</span>, bbox_to_anchor<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1.4</span> ,<span style="color:#ae81ff">1</span>), frameon<span style="color:#f92672">=</span>False)
    <span style="color:#66d9ef">return</span> fig<span style="color:#f92672">.</span>show()
</code></pre></div><h3 id="torsion-potential-after-initial-training">Torsion potential after initial training</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">tor_pot_plot(rel_sp_energies, rel_tor_predict[<span style="color:#ae81ff">0</span>], tor_std_prop[<span style="color:#ae81ff">0</span>], <span style="color:#e6db74">&#34;C6&#34;</span>)
</code></pre></div><p><img src="./active_learning_demo_7_write_files_100_0.png" alt="png"></p>
<h3 id="torsion-potential-after-step-5">Torsion potential after step 5</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">tor_pot_plot(rel_sp_energies, rel_tor_predict[<span style="color:#ae81ff">5</span>], tor_std_prop[<span style="color:#ae81ff">5</span>], <span style="color:#e6db74">&#34;C4&#34;</span>)
</code></pre></div><p><img src="./active_learning_demo_7_write_files_102_0.png" alt="png"></p>
<h3 id="torsion-potential-after-step-10">Torsion potential after step 10</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">tor_pot_plot(rel_sp_energies, rel_tor_predict[<span style="color:#ae81ff">10</span>], tor_std_prop[<span style="color:#ae81ff">10</span>], <span style="color:#e6db74">&#34;C1&#34;</span>)
</code></pre></div><p><img src="./active_learning_demo_7_write_files_104_0.png" alt="png"></p>
<p><strong>Comment on the torsion potential data</strong>: It is possible that the model saw some of these points during training.</p>
<h2 id="predicting-relaxed-torsion-potentials">Predicting relaxed torsion potentials</h2>
<p>All the previous data points are single point energies, meaning that I took the initial relaxed structured, rotated the torsion angles, and calculated the energies without doing another relaxation step. Generally, when calculating a torsion potential, I would constrain the torsion angle of interest and do another relaxation. It turns out this is currently not possible with the xTB/ASE combination, but it is very simple to in xTB without the ASE interface. As a result, I read in the files from xTB. The relaxed molecules are guaranteed</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># read in the relaxed molecules</span>
relax_tor_mols <span style="color:#f92672">=</span> read(<span style="color:#e6db74">&#34;./xtbscan.log&#34;</span>, index<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;:&#34;</span>, format<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;xyz&#34;</span>)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">relax_tor_graphs <span style="color:#f92672">=</span> [Graph<span style="color:#f92672">.</span>from_ase(mol, adjacency<span style="color:#f92672">=</span>adj) <span style="color:#66d9ef">for</span> mol <span style="color:#f92672">in</span> relax_tor_mols]
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># read in the energies</span>
relax_tor_ev_energies <span style="color:#f92672">=</span> []
<span style="color:#66d9ef">with</span> open(<span style="color:#e6db74">&#34;./xtbscan.log&#34;</span>) <span style="color:#66d9ef">as</span> file:
    <span style="color:#66d9ef">for</span> i, line <span style="color:#f92672">in</span> enumerate(file):
        <span style="color:#66d9ef">if</span> <span style="color:#e6db74">&#34;SCF done&#34;</span> <span style="color:#f92672">in</span> line:
            <span style="color:#75715e"># energies are in Hatrees</span>
            tor_ha_energy <span style="color:#f92672">=</span> float(line<span style="color:#f92672">.</span>split()[<span style="color:#ae81ff">2</span>])
            relax_tor_ev_energies<span style="color:#f92672">.</span>append(tor_ha_energy <span style="color:#f92672">*</span> <span style="color:#ae81ff">27.211386245988</span>)  
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># relative energies</span>
rel_relax_tor_energies <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(relax_tor_ev_energies) <span style="color:#f92672">-</span> min(relax_tor_ev_energies)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">relax_tor_predict, relax_tor_std <span style="color:#f92672">=</span> pe_gpr<span style="color:#f92672">.</span>gpr<span style="color:#f92672">.</span>predict(relax_tor_graphs, return_std<span style="color:#f92672">=</span>True)
</code></pre></div><pre><code>      0.5 ms on generating jobs
      0.4 ms on creating output buffer
      0.8 ms on transferring graphs to GPU
      0.1 ms on allocate global job counter
      8.9 ms on code generation
    193.2 ms on JIT
      0.4 ms on calculating launch configuration
      2.0 ms on GPU kernel execution
    205.6 ms on calling GPU kernel (overall)
      0.0 ms on collecting result
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># relative predicted energies</span>
rel_relax_tor_predict <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(relax_tor_predict) <span style="color:#f92672">-</span> min(relax_tor_predict)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># propagate the error (energy – min(energy))</span>
min_i <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>argmin(rel_relax_tor_energies)
relax_tor_std_prop <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>sqrt(np<span style="color:#f92672">.</span>power(relax_tor_std, <span style="color:#ae81ff">2</span>) <span style="color:#f92672">+</span> np<span style="color:#f92672">.</span>power(relax_tor_std[min_i], <span style="color:#ae81ff">2</span>))
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">tor_pot_plot(rel_relax_tor_energies, rel_relax_tor_predict, relax_tor_std_prop, <span style="color:#e6db74">&#34;C2&#34;</span>, ylim<span style="color:#f92672">=</span>(<span style="color:#f92672">-</span><span style="color:#ae81ff">0.1</span>, <span style="color:#ae81ff">0.35</span>))
</code></pre></div><p><img src="./active_learning_demo_7_write_files_115_0.png" alt="png"></p>
<p>Predicting the energy of relaxed structures is not fantastic but the shape of the potential is roughly correct, and the good news is that the model knows what it doesn’t know. The prediction uncertainty for these is high compared to the previous torsion potential predictions. Relaxations cause fluctuations in other degrees of freedom such as bond lengths and bond angles, which the model was not trained on. So, if predicting the energy of relaxed structures is the goal some examples should be included in the training set.</p>
<h1 id="conclusions">Conclusions</h1>
<ul>
<li>The graphs and molecular graph kernel from GraphDot have enough resolution to tell the difference between torsional conformers of the same molecule</li>
<li>Good energy predictions ($&lt;k_BT$) can be achieved on small datasets with the implemented graph kernel and GPR model</li>
<li>Prediction uncertainties are very useful and a huge advantage of a GPR model. Chemistry or materials science problems where generating semi-realistic structures is easy but energy evaluations are expensive are most likely to fully leverage the advantages of GPR.</li>
<li>If predicting the energy of relaxed structures is the objective, at least some relaxed structures should be included in the training dataset</li>
<li>The algorithm presented here will not work for all molecular systems but I think everyone can appreciate the software integration :)</li>
</ul>
<h2 id="future-extensions">Future Extensions</h2>
<ul>
<li>Predicting structures — It would be nice to be able to predict low energy conformations. One way to do this is write an optimizer in ASE and use the GPR model as a surrogate for the energy calculation.</li>
<li>Extrapolation to larger polymers — One potential way to extend the toy example I presented here is to predict the energy of a chain that is roughly the same size as the torsional correlation length. Beyond that length segments are uncorrelated and one might be able to extrapolate energy predictions to much larger polymers.</li>
</ul>
<h2 id="known-issues">Known Issues</h2>
<ul>
<li>The validation and test sets are potentially contaminated, because I did not account for the symmetry present in the example system.</li>
<li>Energies were not calculated on-the-fly in the active learning loop. I did this to keep things simple, but there is no reason it couldn’t be done in the future.</li>
</ul>

    </div>

    




    



  







    
    

    

    


  </div>
</article>

<div class="container">
  <footer class="site-footer">
  

  <p class="powered-by">
    © 2020 Brandon Wood &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

</div>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    
    
    <script src="/js/mathjax-config.js"></script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha512-+NqPlbbtM1QqiK8ZAo4Yrj2c4lNQoGv8P79DPtKzj++l5jnN39rHA/xsqn8zE9l0uSoxaCdrOgFs6yjyfbBxSg==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha256-VsEqElsCHSGmnmHXGQzvoWjWwoznFSZc6hs7ARLRacQ=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    
    

    
    
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "results found",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    
    
    
    
    
    
    
    <script src="/js/academic.min.5752a62e7c04993e8f13fbc193e7a138.js"></script>

    

  </body>
</html>

